<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>CIFAR-100 · MLDatasets.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/documenter.css" rel="stylesheet" type="text/css"/><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><nav class="toc"><a href="../../index.html"><img class="logo" src="../../assets/logo.png" alt="MLDatasets.jl logo"/></a><h1>MLDatasets.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../">Home</a></li><li><span class="toctext">Available Datasets</span><ul><li><span class="toctext">Image Classification</span><ul><li><a class="toctext" href="../MNIST/">MNIST handwritten digits</a></li><li><a class="toctext" href="../FashionMNIST/">Fashion MNIST</a></li><li><a class="toctext" href="../CIFAR10/">CIFAR-10</a></li><li class="current"><a class="toctext" href>CIFAR-100</a><ul class="internal"><li><a class="toctext" href="#Contents-1">Contents</a></li><li><a class="toctext" href="#Overview-1">Overview</a></li><li><a class="toctext" href="#API-Documentation-1">API Documentation</a></li><li><a class="toctext" href="#References-1">References</a></li></ul></li></ul></li></ul></li><li><a class="toctext" href="../../LICENSE/">LICENSE</a></li></ul></nav><article id="docs"><header><nav><ul><li>Available Datasets</li><li>Image Classification</li><li><a href>CIFAR-100</a></li></ul><a class="edit-page" href="https://github.com/JuliaML/MLDatasets.jl/blob/master/docs/src/datasets/CIFAR100.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>CIFAR-100</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="CIFAR100-1" href="#CIFAR100-1">CIFAR-100</a></h1><p>Description from the <a href="https://www.cs.toronto.edu/~kriz/cifar.html">original website</a></p><blockquote><p>The CIFAR-10 and CIFAR-100 are labeled subsets of the <a href="http://people.csail.mit.edu/torralba/tinyimages/">80 million tiny images</a> dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.</p><p>This dataset is just like the CIFAR-10, except it has 100 classes containing 600 images each. There are 500 training images and 100 testing images per class. The 100 classes in the CIFAR-100 are grouped into 20 superclasses. Each image comes with a &quot;fine&quot; label (the class to which it belongs) and a &quot;coarse&quot; label (the superclass to which it belongs).</p></blockquote><h2><a class="nav-anchor" id="Contents-1" href="#Contents-1">Contents</a></h2><ul><li><a href="#CIFAR100-1">CIFAR-100</a></li><ul><li><a href="#Contents-1">Contents</a></li><li><a href="#Overview-1">Overview</a></li><li><a href="#API-Documentation-1">API Documentation</a></li><ul><li><a href="#Trainingset-1">Trainingset</a></li><li><a href="#Testset-1">Testset</a></li><li><a href="#Utilities-1">Utilities</a></li></ul><li><a href="#References-1">References</a></li></ul></ul><h2><a class="nav-anchor" id="Overview-1" href="#Overview-1">Overview</a></h2><p>The <code>MLDatasets.CIFAR100</code> sub-module provides a programmatic interface to download, load, and work with the CIFAR-100 dataset.</p><pre><code class="language-julia">using MLDatasets

# load full training set
train_x, train_y_coarse, train_y_fine = CIFAR100.traindata()

# load full test set
test_x, test_y_coarse, test_y_fine  = CIFAR100.testdata()</code></pre><p>The provided functions also allow for optional arguments, such as the directory <code>dir</code> where the dataset is located, or the specific observation <code>indices</code> that one wants to work with. For more information on the interface take a look at the documentation (e.g. <code>?CIFAR100.traindata</code>).</p><table><tr><th>Function</th><th>Description</th></tr><tr><td><code>download([dir])</code></td><td>Trigger interactive download of the dataset</td></tr><tr><td><a href="#MLDatasets.CIFAR100.classnames_coarse"><code>classnames_coarse()</code></a></td><td>Return the 20 super-class names as a vector of strings</td></tr><tr><td><a href="#MLDatasets.CIFAR100.classnames_fine"><code>classnames_fine()</code></a></td><td>Return the 100 class names as a vector of strings</td></tr><tr><td><a href="#MLDatasets.CIFAR100.traintensor"><code>traintensor([T], [indices]; [dir])</code></a></td><td>Load the training images as an array of eltype <code>T</code></td></tr><tr><td><a href="#MLDatasets.CIFAR100.trainlabels"><code>trainlabels([indices]; [dir])</code></a></td><td>Load the labels for the training images</td></tr><tr><td><a href="#MLDatasets.CIFAR100.testtensor"><code>testtensor([T], [indices]; [dir])</code></a></td><td>Load the test images as an array of eltype <code>T</code></td></tr><tr><td><a href="#MLDatasets.CIFAR100.testlabels"><code>testlabels([indices]; [dir])</code></a></td><td>Load the labels for the test images</td></tr><tr><td><a href="#MLDatasets.CIFAR100.traindata"><code>traindata([T], [indices]; [dir])</code></a></td><td>Load images and labels of the training data</td></tr><tr><td><a href="#MLDatasets.CIFAR100.testdata"><code>testdata([T], [indices]; [dir])</code></a></td><td>Load images and labels of the test data</td></tr></table><p>This module also provides utility functions to make working with the CIFAR-100 dataset in Julia more convenient.</p><table><tr><th>Function</th><th>Description</th></tr><tr><td><a href="../CIFAR10/#MLDatasets.CIFAR10.convert2features"><code>convert2features(array)</code></a></td><td>Convert the CIFAR-100 tensor to a flat feature matrix</td></tr><tr><td><a href="../CIFAR10/#MLDatasets.CIFAR10.convert2image"><code>convert2image(array)</code></a></td><td>Convert the CIFAR-100 tensor/matrix to a colorant array</td></tr></table><p>You can use the function <a href="../CIFAR10/#MLDatasets.CIFAR10.convert2features"><code>convert2features</code></a> to convert the given CIFAR-100 tensor to a feature matrix (or feature vector in the case of a single image). The purpose of this function is to drop the spatial dimensions such that traditional ML algorithms can process the dataset.</p><pre><code class="language-julia">julia&gt; CIFAR100.convert2features(CIFAR100.traintensor()) # full training data
3072×50000 Array{N0f8,2}:
[...]</code></pre><p>To visualize an image or a prediction we provide the function <a href="../CIFAR10/#MLDatasets.CIFAR10.convert2image"><code>convert2image</code></a> to convert the given CIFAR-100 horizontal-major tensor (or feature matrix) to a vertical-major <code>Colorant</code> array.</p><pre><code class="language-julia">julia&gt; CIFAR100.convert2image(CIFAR100.traintensor(1)) # first training image
32×32 Array{RGB{N0f8},2}:
[...]</code></pre><h2><a class="nav-anchor" id="API-Documentation-1" href="#API-Documentation-1">API Documentation</a></h2><h3><a class="nav-anchor" id="Trainingset-1" href="#Trainingset-1">Trainingset</a></h3><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLDatasets.CIFAR100.traintensor" href="#MLDatasets.CIFAR100.traintensor"><code>MLDatasets.CIFAR100.traintensor</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">traintensor([T = N0f8], [indices]; [dir]) -&gt; Array{T}</code></pre><p>Return the CIFAR-100 <strong>training</strong> images corresponding to the given <code>indices</code> as a multi-dimensional array of eltype <code>T</code>. If the corresponding labels are required as well, it is recommended to use <a href="#MLDatasets.CIFAR100.traindata"><code>CIFAR100.traindata</code></a> instead.</p><p>The image(s) is/are returned in the native horizontal-major memory layout as a single numeric array. If <code>T &lt;: Integer</code>, then all values will be within <code>0</code> and <code>255</code>, otherwise the values are scaled to be between <code>0</code> and <code>1</code>.</p><p>If the parameter <code>indices</code> is omitted or an <code>AbstractVector</code>, the images are returned as a 4D array (i.e. a <code>Array{T,4}</code>), in which the first dimension corresponds to the pixel <em>rows</em> (x) of the image, the second dimension to the pixel <em>columns</em> (y) of the image, the third dimension the RGB color channels, and the fourth dimension denotes the index of the image.</p><pre><code class="language-julia-repl">julia&gt; CIFAR100.traintensor() # load all training images
32×32×3×50000 Array{N0f8,4}:
[...]

julia&gt; CIFAR100.traintensor(Float32, 1:3) # first three images as Float32
32×32×3×3 Array{Float32,4}:
[...]</code></pre><p>If <code>indices</code> is an <code>Integer</code>, the single image is returned as <code>Array{T,3}</code> in horizontal-major layout, which means that the first dimension denotes the pixel <em>rows</em> (x), the second dimension denotes the pixel <em>columns</em> (y), and the third dimension the RGB color channels of the image.</p><pre><code class="language-julia-repl">julia&gt; CIFAR100.traintensor(1) # load first training image
32×32×3 Array{N0f8,3}:
[...]</code></pre><p>As mentioned above, the images are returned in the native horizontal-major layout to preserve the original feature ordering. You can use the utility function <a href="../CIFAR10/#MLDatasets.CIFAR10.convert2image"><code>convert2image</code></a> to convert an CIFAR-100 array into a vertical-major Julia image with the appropriate <code>RGB</code> eltype.</p><pre><code class="language-julia-repl">julia&gt; CIFAR100.convert2image(CIFAR100.traintensor(1)) # convert to column-major colorant array
32×32 Array{RGB{N0f8},2}:
[...]</code></pre><p>The corresponding resource file(s) of the dataset is/are expected to be located in the specified directory <code>dir</code>. If <code>dir</code> is omitted the directories in <code>DataDeps.default_loadpath</code> will be searched for an existing <code>CIFAR100</code> subfolder. In case no such subfolder is found, <code>dir</code> will default to <code>~/.julia/datadeps/CIFAR100</code>. In the case that <code>dir</code> does not yet exist, a download prompt will be triggered. You can also use <code>CIFAR100.download([dir])</code> explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaML/MLDatasets.jl/blob/bf211e9f19bec44e84f25f60aa204d9c09ecff84/src/CIFAR100/interface.jl#L29-L84">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLDatasets.CIFAR100.trainlabels" href="#MLDatasets.CIFAR100.trainlabels"><code>MLDatasets.CIFAR100.trainlabels</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">trainlabels([indices]; [dir]) -&gt; Yc, Yf</code></pre><p>Return the CIFAR-100 <strong>trainset</strong> labels (coarse and fine) corresponding to the given <code>indices</code> as a tuple of two <code>Int</code> or two <code>Vector{Int}</code>. The variables returned are the coarse label(s) (<code>Yc</code>) and the fine label(s) (<code>Yf</code>) respectively.</p><pre><code class="language-julia">Yc, Yf = CIFAR100.trainlabels(); # full training set</code></pre><p>The values of the labels denote the zero-based class-index that they represent (see <a href="#MLDatasets.CIFAR100.classnames_coarse"><code>CIFAR100.classnames_coarse</code></a> and <a href="#MLDatasets.CIFAR100.classnames_fine"><code>CIFAR100.classnames_fine</code></a> for the corresponding names). If <code>indices</code> is omitted, all labels are returned.</p><pre><code class="language-julia-repl">julia&gt; Yc, Yf = CIFAR100.trainlabels(1:3) # first three labels
([11, 15, 4], [19, 29, 0])

julia&gt; yc, yf = CIFAR100.trainlabels(1) # first label
(11, 19)

julia&gt; CIFAR100.classnames_coarse()[yc + 1] # corresponding superclass name
&quot;large_omnivores_and_herbivores&quot;

julia&gt; CIFAR100.classnames_fine()[yf + 1] # corresponding class name
&quot;cattle&quot;</code></pre><p>The corresponding resource file(s) of the dataset is/are expected to be located in the specified directory <code>dir</code>. If <code>dir</code> is omitted the directories in <code>DataDeps.default_loadpath</code> will be searched for an existing <code>CIFAR100</code> subfolder. In case no such subfolder is found, <code>dir</code> will default to <code>~/.julia/datadeps/CIFAR100</code>. In the case that <code>dir</code> does not yet exist, a download prompt will be triggered. You can also use <code>CIFAR100.download([dir])</code> explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaML/MLDatasets.jl/blob/bf211e9f19bec44e84f25f60aa204d9c09ecff84/src/CIFAR100/interface.jl#L158-L190">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLDatasets.CIFAR100.traindata" href="#MLDatasets.CIFAR100.traindata"><code>MLDatasets.CIFAR100.traindata</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">traindata([T = N0f8], [indices]; [dir]) -&gt; X, Yc, Yf</code></pre><p>Returns the CIFAR-100 <strong>trainset</strong> corresponding to the given <code>indices</code> as a three-element tuple. If <code>indices</code> is omitted the full trainingset is returned. The first element of three return values (<code>X</code>) will be the images as a multi-dimensional array, the second element (<code>Yc</code>) the corresponding coarse labels as integers, and the third element (<code>Yf</code>) the fine labels respectively.</p><p>The image(s) is/are returned in the native horizontal-major memory layout as a single numeric array of eltype <code>T</code>. If <code>T &lt;: Integer</code>, then all values will be within <code>0</code> and <code>255</code>, otherwise the values are scaled to be between <code>0</code> and <code>1</code>. The integer values of the labels correspond 1-to-1 the digit that they represent.</p><pre><code class="language-julia">X, Yc, Yf = CIFAR100.traindata() # full datatset
X, Yc, Yf = CIFAR100.traindata(dir=&quot;./CIFAR100&quot;) # custom folder
x, yc, yf = CIFAR100.traindata(2) # only second observation</code></pre><p>The corresponding resource file(s) of the dataset is/are expected to be located in the specified directory <code>dir</code>. If <code>dir</code> is omitted the directories in <code>DataDeps.default_loadpath</code> will be searched for an existing <code>CIFAR100</code> subfolder. In case no such subfolder is found, <code>dir</code> will default to <code>~/.julia/datadeps/CIFAR100</code>. In the case that <code>dir</code> does not yet exist, a download prompt will be triggered. You can also use <code>CIFAR100.download([dir])</code> explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.</p><p>Take a look at <a href="#MLDatasets.CIFAR100.traintensor"><code>CIFAR100.traintensor</code></a> and <a href="#MLDatasets.CIFAR100.trainlabels"><code>CIFAR100.trainlabels</code></a> for more information.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaML/MLDatasets.jl/blob/bf211e9f19bec44e84f25f60aa204d9c09ecff84/src/CIFAR100/interface.jl#L234-L262">source</a></section><h3><a class="nav-anchor" id="Testset-1" href="#Testset-1">Testset</a></h3><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLDatasets.CIFAR100.testtensor" href="#MLDatasets.CIFAR100.testtensor"><code>MLDatasets.CIFAR100.testtensor</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">testtensor([T = N0f8], [indices]; [dir]) -&gt; Array{T}</code></pre><p>Return the CIFAR-100 <strong>test</strong> images corresponding to the given <code>indices</code> as a multi-dimensional array of eltype <code>T</code>. If the corresponding labels are required as well, it is recommended to use <a href="#MLDatasets.CIFAR100.testdata"><code>CIFAR100.testdata</code></a> instead.</p><p>The image(s) is/are returned in the native horizontal-major memory layout as a single numeric array. If <code>T &lt;: Integer</code>, then all values will be within <code>0</code> and <code>255</code>, otherwise the values are scaled to be between <code>0</code> and <code>1</code>.</p><p>If the parameter <code>indices</code> is omitted or an <code>AbstractVector</code>, the images are returned as a 4D array (i.e. a <code>Array{T,4}</code>), in which the first dimension corresponds to the pixel <em>rows</em> (x) of the image, the second dimension to the pixel <em>columns</em> (y) of the image, the third dimension the RGB color channels, and the fourth dimension denotes the index of the image.</p><pre><code class="language-julia-repl">julia&gt; CIFAR100.testtensor() # load all training images
32×32×3×10000 Array{N0f8,4}:
[...]

julia&gt; CIFAR100.testtensor(Float32, 1:3) # first three images as Float32
32×32×3×3 Array{Float32,4}:
[...]</code></pre><p>If <code>indices</code> is an <code>Integer</code>, the single image is returned as <code>Array{T,3}</code> in horizontal-major layout, which means that the first dimension denotes the pixel <em>rows</em> (x), the second dimension denotes the pixel <em>columns</em> (y), and the third dimension the RGB color channels of the image.</p><pre><code class="language-julia-repl">julia&gt; CIFAR100.testtensor(1) # load first training image
32×32×3 Array{N0f8,3}:
[...]</code></pre><p>As mentioned above, the images are returned in the native horizontal-major layout to preserve the original feature ordering. You can use the utility function <a href="../CIFAR10/#MLDatasets.CIFAR10.convert2image"><code>convert2image</code></a> to convert an CIFAR-100 array into a vertical-major Julia image with the appropriate <code>RGB</code> eltype.</p><pre><code class="language-julia-repl">julia&gt; CIFAR100.convert2image(CIFAR100.testtensor(1)) # convert to column-major colorant array
32×32 Array{RGB{N0f8},2}:
[...]</code></pre><p>The corresponding resource file(s) of the dataset is/are expected to be located in the specified directory <code>dir</code>. If <code>dir</code> is omitted the directories in <code>DataDeps.default_loadpath</code> will be searched for an existing <code>CIFAR100</code> subfolder. In case no such subfolder is found, <code>dir</code> will default to <code>~/.julia/datadeps/CIFAR100</code>. In the case that <code>dir</code> does not yet exist, a download prompt will be triggered. You can also use <code>CIFAR100.download([dir])</code> explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaML/MLDatasets.jl/blob/bf211e9f19bec44e84f25f60aa204d9c09ecff84/src/CIFAR100/interface.jl#L94-L149">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLDatasets.CIFAR100.testlabels" href="#MLDatasets.CIFAR100.testlabels"><code>MLDatasets.CIFAR100.testlabels</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">testlabels([indices]; [dir]) -&gt; Yc, Yf</code></pre><p>Return the CIFAR-100 <strong>testset</strong> labels (coarse and fine) corresponding to the given <code>indices</code> as a tuple of two <code>Int</code> or two <code>Vector{Int}</code>. The variables returned are the coarse label(s) (<code>Yc</code>) and the fine label(s) (<code>Yf</code>) respectively.</p><pre><code class="language-julia">Yc, Yf = CIFAR100.testlabels(); # full training set</code></pre><p>The values of the labels denote the zero-based class-index that they represent (see <a href="#MLDatasets.CIFAR100.classnames_coarse"><code>CIFAR100.classnames_coarse</code></a> and <a href="#MLDatasets.CIFAR100.classnames_fine"><code>CIFAR100.classnames_fine</code></a> for the corresponding names). If <code>indices</code> is omitted, all labels are returned.</p><pre><code class="language-julia-repl">julia&gt; Yc, Yf = CIFAR100.testlabels(1:3) # first three labels
([10, 10, 0], [49, 33, 72])

julia&gt; yc, yf = CIFAR100.testlabels(1) # first label
(10, 49)

julia&gt; CIFAR100.classnames_coarse()[yc + 1] # corresponding superclass name
&quot;large_natural_outdoor_scenes&quot;

julia&gt; CIFAR100.classnames_fine()[yf + 1] # corresponding class name
&quot;mountain&quot;</code></pre><p>The corresponding resource file(s) of the dataset is/are expected to be located in the specified directory <code>dir</code>. If <code>dir</code> is omitted the directories in <code>DataDeps.default_loadpath</code> will be searched for an existing <code>CIFAR100</code> subfolder. In case no such subfolder is found, <code>dir</code> will default to <code>~/.julia/datadeps/CIFAR100</code>. In the case that <code>dir</code> does not yet exist, a download prompt will be triggered. You can also use <code>CIFAR100.download([dir])</code> explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaML/MLDatasets.jl/blob/bf211e9f19bec44e84f25f60aa204d9c09ecff84/src/CIFAR100/interface.jl#L196-L228">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLDatasets.CIFAR100.testdata" href="#MLDatasets.CIFAR100.testdata"><code>MLDatasets.CIFAR100.testdata</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">testdata([T = N0f8], [indices]; [dir]) -&gt; X, Yc, Yf</code></pre><p>Returns the CIFAR-100 <strong>testset</strong> corresponding to the given <code>indices</code> as a three-element tuple. If <code>indices</code> is omitted the full testset is returned. The first element of three return values (<code>X</code>) will be the images as a multi-dimensional array, the second element (<code>Yc</code>) the corresponding coarse labels as integers, and the third element (<code>Yf</code>) the fine labels respectively.</p><p>The image(s) is/are returned in the native horizontal-major memory layout as a single numeric array of eltype <code>T</code>. If <code>T &lt;: Integer</code>, then all values will be within <code>0</code> and <code>255</code>, otherwise the values are scaled to be between <code>0</code> and <code>1</code>. The integer values of the labels correspond 1-to-1 the digit that they represent.</p><pre><code class="language-julia">X, Yc, Yf = CIFAR100.testdata() # full datatset
X, Yc, Yf = CIFAR100.testdata(dir=&quot;./CIFAR100&quot;) # custom folder
x, yc, yf = CIFAR100.testdata(2) # only second observation</code></pre><p>The corresponding resource file(s) of the dataset is/are expected to be located in the specified directory <code>dir</code>. If <code>dir</code> is omitted the directories in <code>DataDeps.default_loadpath</code> will be searched for an existing <code>CIFAR100</code> subfolder. In case no such subfolder is found, <code>dir</code> will default to <code>~/.julia/datadeps/CIFAR100</code>. In the case that <code>dir</code> does not yet exist, a download prompt will be triggered. You can also use <code>CIFAR100.download([dir])</code> explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.</p><p>Take a look at <a href="#MLDatasets.CIFAR100.testtensor"><code>CIFAR100.testtensor</code></a> and <a href="#MLDatasets.CIFAR100.testlabels"><code>CIFAR100.testlabels</code></a> for more information.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaML/MLDatasets.jl/blob/bf211e9f19bec44e84f25f60aa204d9c09ecff84/src/CIFAR100/interface.jl#L315-L343">source</a></section><h3><a class="nav-anchor" id="Utilities-1" href="#Utilities-1">Utilities</a></h3><p>See <a href="../CIFAR10/#MLDatasets.CIFAR10.convert2features"><code>CIFAR10.convert2features</code></a> and <a href="../CIFAR10/#MLDatasets.CIFAR10.convert2image"><code>CIFAR10.convert2image</code></a></p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLDatasets.CIFAR100.classnames_coarse" href="#MLDatasets.CIFAR100.classnames_coarse"><code>MLDatasets.CIFAR100.classnames_coarse</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">classnames_coarse(; [dir]) -&gt; Vector{String}</code></pre><p>Return the 20 names for the CIFAR100 superclasses as a vector of strings. Note that these strings are read from the actual resource file.</p><p>The corresponding resource file(s) of the dataset is/are expected to be located in the specified directory <code>dir</code>. If <code>dir</code> is omitted the directories in <code>DataDeps.default_loadpath</code> will be searched for an existing <code>CIFAR100</code> subfolder. In case no such subfolder is found, <code>dir</code> will default to <code>~/.julia/datadeps/CIFAR100</code>. In the case that <code>dir</code> does not yet exist, a download prompt will be triggered. You can also use <code>CIFAR100.download([dir])</code> explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaML/MLDatasets.jl/blob/bf211e9f19bec44e84f25f60aa204d9c09ecff84/src/CIFAR100/interface.jl#L1-L9">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLDatasets.CIFAR100.classnames_fine" href="#MLDatasets.CIFAR100.classnames_fine"><code>MLDatasets.CIFAR100.classnames_fine</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">classnames_fine(; [dir]) -&gt; Vector{String}</code></pre><p>Return the 100 names for the CIFAR100 classes as a vector of strings. Note that these strings are read from the actual resource file.</p><p>The corresponding resource file(s) of the dataset is/are expected to be located in the specified directory <code>dir</code>. If <code>dir</code> is omitted the directories in <code>DataDeps.default_loadpath</code> will be searched for an existing <code>CIFAR100</code> subfolder. In case no such subfolder is found, <code>dir</code> will default to <code>~/.julia/datadeps/CIFAR100</code>. In the case that <code>dir</code> does not yet exist, a download prompt will be triggered. You can also use <code>CIFAR100.download([dir])</code> explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaML/MLDatasets.jl/blob/bf211e9f19bec44e84f25f60aa204d9c09ecff84/src/CIFAR100/interface.jl#L15-L23">source</a></section><h2><a class="nav-anchor" id="References-1" href="#References-1">References</a></h2><ul><li><p><strong>Authors</strong>: Alex Krizhevsky, Vinod Nair, Geoffrey Hinton</p></li><li><p><strong>Website</strong>: https://www.cs.toronto.edu/~kriz/cifar.html</p></li><li><p><strong>[Krizhevsky, 2009]</strong> Alex Krizhevsky. <a href="https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf">&quot;Learning Multiple Layers of Features from Tiny Images&quot;</a>, Tech Report, 2009.</p></li></ul><footer><hr/><a class="previous" href="../CIFAR10/"><span class="direction">Previous</span><span class="title">CIFAR-10</span></a><a class="next" href="../../indices/"><span class="direction">Next</span><span class="title">Indices</span></a></footer></article></body></html>

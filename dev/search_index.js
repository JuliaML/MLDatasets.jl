var documenterSearchIndex = {"docs":
[{"location":"datasets/FashionMNIST/#FashionMNIST","page":"FashionMNIST","title":"Fashion-MNIST","text":"","category":"section"},{"location":"datasets/FashionMNIST/","page":"FashionMNIST","title":"FashionMNIST","text":"Description from the official website","category":"page"},{"location":"datasets/FashionMNIST/","page":"FashionMNIST","title":"FashionMNIST","text":"Fashion-MNIST is a dataset of Zalando's article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.","category":"page"},{"location":"datasets/FashionMNIST/#Contents","page":"FashionMNIST","title":"Contents","text":"","category":"section"},{"location":"datasets/FashionMNIST/","page":"FashionMNIST","title":"FashionMNIST","text":"Pages = [\"FashionMNIST.md\"]\nDepth = 3","category":"page"},{"location":"datasets/FashionMNIST/#Overview","page":"FashionMNIST","title":"Overview","text":"","category":"section"},{"location":"datasets/FashionMNIST/","page":"FashionMNIST","title":"FashionMNIST","text":"The MLDatasets.FashionMNIST sub-module provides a programmatic interface to download, load, and work with the Fashion-MNIST dataset.","category":"page"},{"location":"datasets/FashionMNIST/","page":"FashionMNIST","title":"FashionMNIST","text":"using MLDatasets\n\n# load full training set\ntrain_x, train_y = FashionMNIST.traindata()\n\n# load full test set\ntest_x,  test_y  = FashionMNIST.testdata()","category":"page"},{"location":"datasets/FashionMNIST/","page":"FashionMNIST","title":"FashionMNIST","text":"The provided functions also allow for optional arguments, such as the directory dir where the dataset is located, or the specific observation indices that one wants to work with. For more information on the interface take a look at the documentation (e.g. ?FashionMNIST.traindata).","category":"page"},{"location":"datasets/FashionMNIST/","page":"FashionMNIST","title":"FashionMNIST","text":"Function Description\ndownload([dir]) Trigger (interactive) download of the dataset\nclassnames() Return the class names as a vector of strings\ntraintensor([T], [indices]; [dir]) Load the training images as an array of eltype T\ntrainlabels([indices]; [dir]) Load the labels for the training images\ntesttensor([T], [indices]; [dir]) Load the test images as an array of eltype T\ntestlabels([indices]; [dir]) Load the labels for the test images\ntraindata([T], [indices]; [dir]) Load images and labels of the training data\ntestdata([T], [indices]; [dir]) Load images and labels of the test data","category":"page"},{"location":"datasets/FashionMNIST/","page":"FashionMNIST","title":"FashionMNIST","text":"This module also provides utility functions to make working with the Fashion-MNIST dataset in Julia more convenient.","category":"page"},{"location":"datasets/FashionMNIST/","page":"FashionMNIST","title":"FashionMNIST","text":"Function Description\nconvert2image(array) Convert the Fashion-MNIST tensor/matrix to a colorant array","category":"page"},{"location":"datasets/FashionMNIST/","page":"FashionMNIST","title":"FashionMNIST","text":"To visualize an image or a prediction we provide the function convert2image to convert the given Fashion-MNIST horizontal-major tensor (or feature matrix) to a vertical-major Colorant array. The values are also color corrected according to the website's description, which means that the digits are black on a white background.","category":"page"},{"location":"datasets/FashionMNIST/","page":"FashionMNIST","title":"FashionMNIST","text":"julia> FashionMNIST.convert2image(FashionMNIST.traintensor(1)) # first training image\n28×28 Array{Gray{N0f8},2}:\n[...]","category":"page"},{"location":"datasets/FashionMNIST/#API-Documentation","page":"FashionMNIST","title":"API Documentation","text":"","category":"section"},{"location":"datasets/FashionMNIST/","page":"FashionMNIST","title":"FashionMNIST","text":"FashionMNIST","category":"page"},{"location":"datasets/FashionMNIST/#MLDatasets.FashionMNIST","page":"FashionMNIST","title":"MLDatasets.FashionMNIST","text":"Fashion-MNIST\n\nAuthors: Han Xiao, Kashif Rasul, Roland Vollgraf\nWebsite: https://github.com/zalandoresearch/fashion-mnist\n\nFashion-MNIST is a dataset of Zalando's article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. It can serve as a drop-in replacement for MNIST.\n\nInterface\n\nFashionMNIST.traintensor, FashionMNIST.trainlabels, FashionMNIST.traindata\nFashionMNIST.testtensor, FashionMNIST.testlabels, FashionMNIST.testdata\n\nUtilities\n\nFashionMNIST.download\n\nAlso, the FashionMNIST module is re-exporting convert2image from the MNIST module.\n\n\n\n\n\n","category":"module"},{"location":"datasets/FashionMNIST/#Trainingset","page":"FashionMNIST","title":"Trainingset","text":"","category":"section"},{"location":"datasets/FashionMNIST/","page":"FashionMNIST","title":"FashionMNIST","text":"FashionMNIST.traintensor\nFashionMNIST.trainlabels\nFashionMNIST.traindata","category":"page"},{"location":"datasets/FashionMNIST/#MLDatasets.FashionMNIST.traintensor","page":"FashionMNIST","title":"MLDatasets.FashionMNIST.traintensor","text":"traintensor([T = N0f8], [indices]; [dir]) -> Array{T}\n\nSame as MNIST.traintensor but for the FashionMNIST dataset.\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing FashionMNIST subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/FashionMNIST. In the case that dir does not yet exist, a download prompt will be triggered. You can also use FashionMNIST.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/FashionMNIST/#MLDatasets.FashionMNIST.trainlabels","page":"FashionMNIST","title":"MLDatasets.FashionMNIST.trainlabels","text":"trainlabels([indices]; [dir])\n\nReturns the Fashion-MNIST trainset labels corresponding to the given indices as an Int or Vector{Int}. The values of the labels denote the zero-based class-index that they represent (see FashionMNIST.classnames for the corresponding names). If indices is omitted, all labels are returned.\n\njulia> FashionMNIST.trainlabels() # full training set\n60000-element Array{Int64,1}:\n 9\n 0\n ⋮\n 0\n 5\n\njulia> FashionMNIST.trainlabels(1:3) # first three labels\n3-element Array{Int64,1}:\n 9\n 0\n 0\n\njulia> y = FashionMNIST.trainlabels(1) # first label\n9\n\njulia> FashionMNIST.classnames()[y + 1] # corresponding name\n\"Ankle boot\"\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing FashionMNIST subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/FashionMNIST. In the case that dir does not yet exist, a download prompt will be triggered. You can also use FashionMNIST.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/FashionMNIST/#MLDatasets.FashionMNIST.traindata","page":"FashionMNIST","title":"MLDatasets.FashionMNIST.traindata","text":"traindata([T = N0f8], [indices]; [dir]) -> images, labels\n\nSame as MNIST.traindata but for the FashionMNIST dataset.\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing FashionMNIST subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/FashionMNIST. In the case that dir does not yet exist, a download prompt will be triggered. You can also use FashionMNIST.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\nTake a look at FashionMNIST.traintensor and FashionMNIST.trainlabels for more information.\n\n\n\n\n\n","category":"function"},{"location":"datasets/FashionMNIST/#Testset","page":"FashionMNIST","title":"Testset","text":"","category":"section"},{"location":"datasets/FashionMNIST/","page":"FashionMNIST","title":"FashionMNIST","text":"FashionMNIST.testtensor\nFashionMNIST.testlabels\nFashionMNIST.testdata","category":"page"},{"location":"datasets/FashionMNIST/#MLDatasets.FashionMNIST.testtensor","page":"FashionMNIST","title":"MLDatasets.FashionMNIST.testtensor","text":"testtensor([T = N0f8], [indices]; [dir]) -> Array{T}\n\nSame as MNIST.testtensor but for the FashionMNIST dataset. ```\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing FashionMNIST subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/FashionMNIST. In the case that dir does not yet exist, a download prompt will be triggered. You can also use FashionMNIST.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/FashionMNIST/#MLDatasets.FashionMNIST.testlabels","page":"FashionMNIST","title":"MLDatasets.FashionMNIST.testlabels","text":"testlabels([indices]; [dir])\n\nReturns the Fashion-MNIST testset labels corresponding to the given indices as an Int or Vector{Int}. The values of the labels denote the class-index that they represent (see FashionMNIST.classnames for the corresponding names). If indices is omitted, all labels are returned.\n\njulia> FashionMNIST.testlabels() # full test set\n10000-element Array{Int64,1}:\n 9\n 2\n ⋮\n 1\n 5\n\njulia> FashionMNIST.testlabels(1:3) # first three labels\n3-element Array{Int64,1}:\n 9\n 2\n 1\n\njulia> y = FashionMNIST.testlabels(1) # first label\n9\n\njulia> FashionMNIST.classnames()[y + 1] # corresponding name\n\"Ankle boot\"\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing FashionMNIST subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/FashionMNIST. In the case that dir does not yet exist, a download prompt will be triggered. You can also use FashionMNIST.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/FashionMNIST/#MLDatasets.FashionMNIST.testdata","page":"FashionMNIST","title":"MLDatasets.FashionMNIST.testdata","text":"testdata([T = N0f8], [indices]; [dir]) -> images, labels\n\nSame as MNIST.testdata but for the FashionMNIST dataset.\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing FashionMNIST subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/FashionMNIST. In the case that dir does not yet exist, a download prompt will be triggered. You can also use FashionMNIST.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\nTake a look at FashionMNIST.testtensor and FashionMNIST.testlabels for more information.\n\n\n\n\n\n","category":"function"},{"location":"datasets/FashionMNIST/#Utilities","page":"FashionMNIST","title":"Utilities","text":"","category":"section"},{"location":"datasets/FashionMNIST/","page":"FashionMNIST","title":"FashionMNIST","text":"FashionMNIST.download\nFashionMNIST.classnames","category":"page"},{"location":"datasets/FashionMNIST/#MLDatasets.FashionMNIST.download","page":"FashionMNIST","title":"MLDatasets.FashionMNIST.download","text":"download([dir]; [i_accept_the_terms_of_use])\n\nTrigger the (interactive) download of the full dataset into \"dir\". If no dir is provided the dataset will be downloaded into \"~/.julia/datadeps/FashionMNIST\".\n\nThis function will display an interactive dialog unless either the keyword parameter i_accept_the_terms_of_use or the environment variable DATADEPS_ALWAYS_ACCEPT is set to true. Note that using the data responsibly and respecting copyright/terms-of-use remains your responsibility.\n\n\n\n\n\n","category":"function"},{"location":"datasets/FashionMNIST/#MLDatasets.FashionMNIST.classnames","page":"FashionMNIST","title":"MLDatasets.FashionMNIST.classnames","text":"classnames() -> Vector{String}\n\nReturn the 10 names for the Fashion-MNIST classes as a vector of strings.\n\n\n\n\n\n","category":"function"},{"location":"datasets/FashionMNIST/","page":"FashionMNIST","title":"FashionMNIST","text":"Also, the FashionMNIST module is re-exporting convert2image from the MNIST module.","category":"page"},{"location":"datasets/FashionMNIST/#References","page":"FashionMNIST","title":"References","text":"","category":"section"},{"location":"datasets/FashionMNIST/","page":"FashionMNIST","title":"FashionMNIST","text":"Authors: Han Xiao, Kashif Rasul, Roland Vollgraf\nWebsite: https://github.com/zalandoresearch/fashion-mnist\n[Han Xiao et al. 2017] Han Xiao, Kashif Rasul, and Roland Vollgraf. \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms.\" arXiv:1708.07747","category":"page"},{"location":"datasets/MNIST/#MNIST","page":"MNIST","title":"The MNIST database of handwritten digits","text":"","category":"section"},{"location":"datasets/MNIST/","page":"MNIST","title":"MNIST","text":"Description from the official website:","category":"page"},{"location":"datasets/MNIST/","page":"MNIST","title":"MNIST","text":"The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.","category":"page"},{"location":"datasets/MNIST/#Contents","page":"MNIST","title":"Contents","text":"","category":"section"},{"location":"datasets/MNIST/","page":"MNIST","title":"MNIST","text":"Pages = [\"MNIST.md\"]\nDepth = 3","category":"page"},{"location":"datasets/MNIST/#Overview","page":"MNIST","title":"Overview","text":"","category":"section"},{"location":"datasets/MNIST/","page":"MNIST","title":"MNIST","text":"The MLDatasets.MNIST sub-module provides a programmatic interface to download, load, and work with the MNIST dataset of handwritten digits.","category":"page"},{"location":"datasets/MNIST/","page":"MNIST","title":"MNIST","text":"using MLDatasets\n\n# load full training set\ntrain_x, train_y = MNIST.traindata()\n\n# load full test set\ntest_x,  test_y  = MNIST.testdata()","category":"page"},{"location":"datasets/MNIST/","page":"MNIST","title":"MNIST","text":"The provided functions also allow for optional arguments, such as the directory dir where the dataset is located, or the specific observation indices that one wants to work with. For more information on the interface take a look at the documentation (e.g. ?MNIST.traindata).","category":"page"},{"location":"datasets/MNIST/","page":"MNIST","title":"MNIST","text":"Function Description\ndownload([dir]) Trigger (interactive) download of the dataset\ntraintensor([T], [indices]; [dir]) Load the training images as an array of eltype T\ntrainlabels([indices]; [dir]) Load the labels for the training images\ntesttensor([T], [indices]; [dir]) Load the test images as an array of eltype T\ntestlabels([indices]; [dir]) Load the labels for the test images\ntraindata([T], [indices]; [dir]) Load images and labels of the training data\ntestdata([T], [indices]; [dir]) Load images and labels of the test data","category":"page"},{"location":"datasets/MNIST/","page":"MNIST","title":"MNIST","text":"This module also provides utility functions to make working with the MNIST dataset in Julia more convenient.","category":"page"},{"location":"datasets/MNIST/","page":"MNIST","title":"MNIST","text":"Function Description\nconvert2image(array) Convert the MNIST tensor/matrix to a colorant array","category":"page"},{"location":"datasets/MNIST/","page":"MNIST","title":"MNIST","text":"To visualize an image or a prediction we provide the function convert2image to convert the given MNIST horizontal-major tensor (or feature matrix) to a vertical-major Colorant array. The values are also color corrected according to the website's description, which means that the digits are black on a white background.","category":"page"},{"location":"datasets/MNIST/","page":"MNIST","title":"MNIST","text":"julia> MNIST.convert2image(MNIST.traintensor(1)) # first training image\n28×28 Array{Gray{N0f8},2}:\n[...]","category":"page"},{"location":"datasets/MNIST/#API-Documentation","page":"MNIST","title":"API Documentation","text":"","category":"section"},{"location":"datasets/MNIST/","page":"MNIST","title":"MNIST","text":"MNIST","category":"page"},{"location":"datasets/MNIST/#MLDatasets.MNIST","page":"MNIST","title":"MLDatasets.MNIST","text":"The MNIST database of handwritten digits\n\nAuthors: Yann LeCun, Corinna Cortes, Christopher J.C. Burges\nWebsite: http://yann.lecun.com/exdb/mnist/\n\nMNIST is a classic image-classification dataset that is often used in small-scale machine learning experiments. It contains 70,000 images of handwritten digits. Each observation is a 28x28 pixel gray-scale image that depicts a handwritten version of 1 of the 10 possible digits (0-9).\n\nInterface\n\nMNIST.traintensor, MNIST.trainlabels, MNIST.traindata\nMNIST.testtensor, MNIST.testlabels, MNIST.testdata\n\nUtilities\n\nMNIST.download\nMNIST.convert2image\n\n\n\n\n\n","category":"module"},{"location":"datasets/MNIST/#Trainingset","page":"MNIST","title":"Trainingset","text":"","category":"section"},{"location":"datasets/MNIST/","page":"MNIST","title":"MNIST","text":"MNIST.traintensor\nMNIST.trainlabels\nMNIST.traindata","category":"page"},{"location":"datasets/MNIST/#MLDatasets.MNIST.traintensor","page":"MNIST","title":"MLDatasets.MNIST.traintensor","text":"traintensor([T = N0f8], [indices]; [dir]) -> Array{T}\n\nReturns the MNIST training images corresponding to the given indices as a multi-dimensional array of eltype T.\n\nThe image(s) is/are returned in the horizontal-major memory layout as a single numeric array. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1.\n\nIf the parameter indices is omitted or an AbstractVector, the images are returned as a 3D array (i.e. a Array{T,3}), in WHN format (width, height, #images).  For integer indices instead, a 2D array in WH format is returned.\n\njulia> MNIST.traintensor() # load all training images\n28×28×60000 Array{N0f8,3}:\n[...]\n\njulia> MNIST.traintensor(Float32, 1:3) # first three images as Float32\n28×28×3 Array{Float32,3}:\n[...]\n\nIf indices is an Integer, the single image is returned as Matrix{T}.\n\njulia> MNIST.traintensor(1) # load first training image\n28×28 Array{N0f8,2}:\n[...]\n\nYou can use the utility function convert2image to convert an MNIST array into a vertical-major Julia image with the corrected color values.\n\njulia> MNIST.convert2image(MNIST.traintensor(1)) # convert to column-major colorant array\n28×28 Array{Gray{N0f8},2}:\n[...]\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing MNIST subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/MNIST. In the case that dir does not yet exist, a download prompt will be triggered. You can also use MNIST.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/MNIST/#MLDatasets.MNIST.trainlabels","page":"MNIST","title":"MLDatasets.MNIST.trainlabels","text":"trainlabels([indices]; [dir])\n\nReturns the MNIST trainset labels corresponding to the given indices as an Int or Vector{Int}. The values of the labels denote the digit that they represent. If indices is omitted, all labels are returned.\n\njulia> MNIST.trainlabels() # full training set\n60000-element Array{Int64,1}:\n 5\n 0\n ⋮\n 6\n 8\n\njulia> MNIST.trainlabels(1:3) # first three labels\n3-element Array{Int64,1}:\n 5\n 0\n 4\n\njulia> MNIST.trainlabels(1) # first label\n5\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing MNIST subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/MNIST. In the case that dir does not yet exist, a download prompt will be triggered. You can also use MNIST.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/MNIST/#MLDatasets.MNIST.traindata","page":"MNIST","title":"MLDatasets.MNIST.traindata","text":"traindata([T = N0f8], [indices]; [dir]) -> Tuple\n\nReturns the MNIST trainingset corresponding to the given indices as a two-element tuple. If indices is omitted the full trainingset is returned. The first element of three return values will be the images as a multi-dimensional array, and the second element the corresponding labels as integers.\n\nThe image(s) is/are returned in the horizontal-major memory layout as a single numeric array of eltype T. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1. The integer values of the labels correspond 1-to-1 the digit that they represent.\n\ntrain_x, train_y = MNIST.traindata() # full datatset\ntrain_x, train_y = MNIST.traindata(2) # only second observation\ntrain_x, train_y = MNIST.traindata(dir=\"./MNIST\") # custom folder\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing MNIST subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/MNIST. In the case that dir does not yet exist, a download prompt will be triggered. You can also use MNIST.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\nTake a look at MNIST.traintensor and MNIST.trainlabels for more information.\n\n\n\n\n\n","category":"function"},{"location":"datasets/MNIST/#Testset","page":"MNIST","title":"Testset","text":"","category":"section"},{"location":"datasets/MNIST/","page":"MNIST","title":"MNIST","text":"MNIST.testtensor\nMNIST.testlabels\nMNIST.testdata","category":"page"},{"location":"datasets/MNIST/#MLDatasets.MNIST.testtensor","page":"MNIST","title":"MLDatasets.MNIST.testtensor","text":"testtensor([T = N0f8], [indices]; [dir]) -> Array{T}\n\nReturns the MNIST test images corresponding to the given indices as a multi-dimensional array of eltype T.\n\nThe image(s) is/are returned in the horizontal-major memory layout as a single numeric array. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1.\n\nIf the parameter indices is omitted or an AbstractVector, the images are returned as a 3D array (i.e. a Array{T,3}), in WHN format (width, height, #images).  For integer indices instead, a 2D array in WH format is returned.\n\njulia> MNIST.testtensor() # load all test images\n28×28×10000 Array{N0f8,3}:\n[...]\n\njulia> MNIST.testtensor(Float32, 1:3) # first three images as Float32\n28×28×3 Array{Float32,3}:\n[...]\n\nIf indices is an Integer, the single image is returned as Matrix{T}.\n\njulia> MNIST.testtensor(1) # load first test image\n28×28 Array{N0f8,2}:\n[...]\n\nYou can use the utility function convert2image to convert an MNIST array into a vertical-major Julia image with the corrected color values.\n\njulia> MNIST.convert2image(MNIST.testtensor(1)) # convert to column-major colorant array\n28×28 Array{Gray{N0f8},2}:\n[...]\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing MNIST subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/MNIST. In the case that dir does not yet exist, a download prompt will be triggered. You can also use MNIST.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/MNIST/#MLDatasets.MNIST.testlabels","page":"MNIST","title":"MLDatasets.MNIST.testlabels","text":"testlabels([indices]; [dir])\n\nReturns the MNIST testset labels corresponding to the given indices as an Int or Vector{Int}. The values of the labels denote the digit that they represent. If indices is omitted, all labels are returned.\n\njulia> MNIST.testlabels() # full test set\n10000-element Array{Int64,1}:\n 7\n 2\n ⋮\n 5\n 6\n\njulia> MNIST.testlabels(1:3) # first three labels\n3-element Array{Int64,1}:\n 7\n 2\n 1\n\njulia> MNIST.testlabels(1) # first label\n7\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing MNIST subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/MNIST. In the case that dir does not yet exist, a download prompt will be triggered. You can also use MNIST.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/MNIST/#MLDatasets.MNIST.testdata","page":"MNIST","title":"MLDatasets.MNIST.testdata","text":"testdata([T = N0f8], [indices]; [dir]) -> Tuple\n\nReturns the MNIST testset corresponding to the given indices as a two-element tuple. If indices is omitted the full testset is returned. The first element of three return values will be the images as a multi-dimensional array, and the second element the corresponding labels as integers.\n\nThe image(s) is/are returned in the horizontal-major memory layout as a single numeric array of eltype T. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1. The integer values of the labels correspond 1-to-1 the digit that they represent.\n\ntest_x, test_y = MNIST.testdata() # full datatset\ntest_x, test_y = MNIST.testdata(2) # only second observation\ntest_x, test_y = MNIST.testdata(dir=\"./MNIST\") # custom folder\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing MNIST subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/MNIST. In the case that dir does not yet exist, a download prompt will be triggered. You can also use MNIST.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\nTake a look at MNIST.testtensor and MNIST.testlabels for more information.\n\n\n\n\n\n","category":"function"},{"location":"datasets/MNIST/#Utilities","page":"MNIST","title":"Utilities","text":"","category":"section"},{"location":"datasets/MNIST/","page":"MNIST","title":"MNIST","text":"MNIST.download\nMNIST.convert2image","category":"page"},{"location":"datasets/MNIST/#MLDatasets.MNIST.download","page":"MNIST","title":"MLDatasets.MNIST.download","text":"download([dir]; [i_accept_the_terms_of_use])\n\nTrigger the (interactive) download of the full dataset into \"dir\". If no dir is provided the dataset will be downloaded into \"~/.julia/datadeps/MNIST\".\n\nThis function will display an interactive dialog unless either the keyword parameter i_accept_the_terms_of_use or the environment variable DATADEPS_ALWAYS_ACCEPT is set to true. Note that using the data responsibly and respecting copyright/terms-of-use remains your responsibility.\n\n\n\n\n\n","category":"function"},{"location":"datasets/MNIST/#MLDatasets.MNIST.convert2image","page":"MNIST","title":"MLDatasets.MNIST.convert2image","text":"convert2image(array; black_digits=false) -> Array{Gray}\n\nConvert the given MNIST horizontal-major tensor (or feature matrix) to a vertical-major Colorant array. If black_digits is true, the values are also color corrected according to the website's description, which means that the digits are black on a white background.\n\njulia> MNIST.convert2image(MNIST.traintensor()) # full training dataset\n28×28×60000 Array{Gray{N0f8},3}:\n[...]\n\njulia> MNIST.convert2image(MNIST.traintensor(1)) # first training image\n28×28 Array{Gray{N0f8},2}:\n[...]\n\n\n\n\n\n","category":"function"},{"location":"datasets/MNIST/#Reader-Sub-module","page":"MNIST","title":"Reader Sub-module","text":"","category":"section"},{"location":"datasets/MNIST/","page":"MNIST","title":"MNIST","text":"Modules = [MLDatasets.MNIST.Reader]\nOrder   = [:function]","category":"page"},{"location":"datasets/MNIST/#MLDatasets.MNIST.Reader.readimageheader-Tuple{AbstractString}","page":"MNIST","title":"MLDatasets.MNIST.Reader.readimageheader","text":"readimageheader(file::AbstractString)\n\nOpens and reads the first four 32 bits values of file and returns them interpreted as an MNIST-image-file header\n\n\n\n\n\n","category":"method"},{"location":"datasets/MNIST/#MLDatasets.MNIST.Reader.readimageheader-Tuple{IO}","page":"MNIST","title":"MLDatasets.MNIST.Reader.readimageheader","text":"readimageheader(io::IO)\n\nReads four 32 bit integers at the current position of io and interprets them as a MNIST-image-file header, which is described in detail in the table below\n\n        ║     First    │  Second  │  Third  │   Fourth\n════════╬══════════════╪══════════╪═════════╪════════════\noffset  ║         0000 │     0004 │    0008 │       0012\ndescr   ║ magic number │ # images │  # rows │  # columns\n\nThese four numbers are returned as a Tuple in the same storage order\n\n\n\n\n\n","category":"method"},{"location":"datasets/MNIST/#MLDatasets.MNIST.Reader.readimages-Tuple{IO, AbstractVector, Integer, Integer}","page":"MNIST","title":"MLDatasets.MNIST.Reader.readimages","text":"readimages(io::IO, indices::AbstractVector, nrows::Integer, ncols::Integer)\n\nReads the first nrows * ncols bytes for each image index in indices and stores them in a Array{UInt8,3} of size (nrows, ncols, length(indices)) in the same order as denoted by indices.\n\n\n\n\n\n","category":"method"},{"location":"datasets/MNIST/#MLDatasets.MNIST.Reader.readimages-Tuple{IO, Any}","page":"MNIST","title":"MLDatasets.MNIST.Reader.readimages","text":"readimages(file, [indices])\n\nReads the images denoted by indices from file. The given file can either be specified using an IO-stream or a string that denotes the fully qualified path. The conent of file is assumed to be in the MNIST image-file format, as it is described on the official homepage at http://yann.lecun.com/exdb/mnist/\n\nif indices is an Integer, the single image is returned as Matrix{UInt8} in horizontal major layout, which means that the first dimension denotes the pixel rows (x), and the second dimension denotes the pixel columns (y) of the image.\nif indices is a AbstractVector, the images are returned as a 3D array (i.e. a Array{UInt8,3}), in which the first dimension corresponds to the pixel rows (x) of the image, the second dimension to the pixel columns (y) of the image, and the third dimension denotes the index of the image.\nif indices is ommited all images are returned (as 3D array described above)\n\n\n\n\n\n","category":"method"},{"location":"datasets/MNIST/#MLDatasets.MNIST.Reader.readimages-Tuple{IO, Integer, Integer, Integer}","page":"MNIST","title":"MLDatasets.MNIST.Reader.readimages","text":"readimages(io::IO, index::Integer, nrows::Integer, ncols::Integer)\n\nJumps to the position of io where the bytes for the index'th image are located and reads the next nrows * ncols bytes. The read bytes are returned as a Matrix{UInt8} of size (nrows, ncols).\n\n\n\n\n\n","category":"method"},{"location":"datasets/MNIST/#MLDatasets.MNIST.Reader.readlabelheader-Tuple{AbstractString}","page":"MNIST","title":"MLDatasets.MNIST.Reader.readlabelheader","text":"readlabelheader(file::AbstractString)\n\nOpens and reads the first two 32 bits values of file and returns them interpreted as an MNIST-label-file header\n\n\n\n\n\n","category":"method"},{"location":"datasets/MNIST/#MLDatasets.MNIST.Reader.readlabelheader-Tuple{IO}","page":"MNIST","title":"MLDatasets.MNIST.Reader.readlabelheader","text":"readlabelheader(io::IO)\n\nReads two 32 bit integers at the current position of io and interprets them as a MNIST-label-file header, which consists of a magic number and the total number of labels stored in the file. These two numbers are returned as a Tuple in the same storage order.\n\n\n\n\n\n","category":"method"},{"location":"datasets/MNIST/#MLDatasets.MNIST.Reader.readlabels-Tuple{AbstractString, Integer}","page":"MNIST","title":"MLDatasets.MNIST.Reader.readlabels","text":"readlabels(file::AbstractString, [indices])\n\nReads the label denoted by indices from file. The given file is assumed to be in the MNIST label-file format, as it is described on the official homepage at http://yann.lecun.com/exdb/mnist/\n\nif indices is an Integer, the single label is returned as UInt8.\nif indices is a AbstractVector, the labels are returned as a Vector{UInt8}, length length(indices) in the same order as denoted by indices.\nif indices is ommited all all are returned (as Vector{UInt8} as described above)\n\n\n\n\n\n","category":"method"},{"location":"datasets/MNIST/#MLDatasets.MNIST.Reader.readlabels-Tuple{IO, AbstractVector}","page":"MNIST","title":"MLDatasets.MNIST.Reader.readlabels","text":"readlabels(io::IO, indices::AbstractVector)\n\nReads the byte for each label-index in indices and stores them in a Vector{UInt8} of length length(indices) in the same order as denoted by indices.\n\n\n\n\n\n","category":"method"},{"location":"datasets/MNIST/#MLDatasets.MNIST.Reader.readlabels-Tuple{IO, Integer}","page":"MNIST","title":"MLDatasets.MNIST.Reader.readlabels","text":"readlabels(io::IO, index::Integer)\n\nJumps to the position of io where the byte for the index'th label is located and returns the byte at that position as UInt8\n\n\n\n\n\n","category":"method"},{"location":"datasets/MNIST/#References","page":"MNIST","title":"References","text":"","category":"section"},{"location":"datasets/MNIST/","page":"MNIST","title":"MNIST","text":"Authors: Yann LeCun, Corinna Cortes, Christopher J.C. Burges\nWebsite: http://yann.lecun.com/exdb/mnist/\n[LeCun et al., 1998a] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998","category":"page"},{"location":"datasets/BostonHousing/#Boston-Housing","page":"Boston Housing","title":"Boston Housing","text":"","category":"section"},{"location":"datasets/BostonHousing/","page":"Boston Housing","title":"Boston Housing","text":"BostonHousing","category":"page"},{"location":"datasets/BostonHousing/#MLDatasets.BostonHousing","page":"Boston Housing","title":"MLDatasets.BostonHousing","text":"Boston Housing Dataset.\n\nSources:    (a) Origin:  This dataset was taken from the StatLib library which is                 maintained at Carnegie Mellon University.    (b) Creator:  Harrison, D. and Rubinfeld, D.L. 'Hedonic prices and the                   demand for clean air', J. Environ. Economics & Management,                  vol.5, 81-102, 1978.    (c) Date: July 7, 1993\n\nNumber of Instances: 506\n\nNumber of Attributes: 13 continuous attributes (including target                             attribute \"MEDV\"), 1 binary-valued attribute.\n\nFeatures:\n\n1. CRIM      per capita crime rate by town\n2. ZN        proportion of residential land zoned for lots over 25,000 sq.ft.\n3. INDUS     proportion of non-retail business acres per town\n4. CHAS      Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n5. NOX       nitric oxides concentration (parts per 10 million)\n6. RM        average number of rooms per dwelling\n7. AGE       proportion of owner-occupied units built prior to 1940\n8. DIS       weighted distances to five Boston employment centres\n9. RAD       index of accessibility to radial highways\n10. TAX      full-value property-tax rate per 10,000 dollars\n11. PTRATIO  pupil-teacher ratio by town\n12. B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n13. LSTAT    % lower status of the population\n\nTarget:\n\n14. MEDV     Median value of owner-occupied homes in 1000's of dollars\n\nNote: Variable #14 seems to be censored at 50.00 (corresponding to a median price of $50,000);  Censoring is suggested by the fact that the highest median price of exactly $50,000 is reported in 16 cases,  while 15 cases have prices between $40,000 and $50,000, with prices rounded to the nearest hundred.  Harrison and Rubinfeld do not mention any censoring.\n\nThe data file stored in this repo is a copy of the This is a copy of UCI ML housing dataset.  https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n\nInterface\n\nBostonHousing.features\nBostonHousing.targets\nBostonHousing.feature_names\n\n\n\n\n\n","category":"module"},{"location":"datasets/BostonHousing/#API-reference","page":"Boston Housing","title":"API reference","text":"","category":"section"},{"location":"datasets/BostonHousing/","page":"Boston Housing","title":"Boston Housing","text":"BostonHousing.feature_names\nBostonHousing.features\nBostonHousing.targets","category":"page"},{"location":"datasets/BostonHousing/#MLDatasets.BostonHousing.feature_names","page":"Boston Housing","title":"MLDatasets.BostonHousing.feature_names","text":"feature_names()\n\nReturn the  the names of the features provided in the dataset.\n\n\n\n\n\n","category":"function"},{"location":"datasets/BostonHousing/#MLDatasets.BostonHousing.features","page":"Boston Housing","title":"MLDatasets.BostonHousing.features","text":"features()\n\nReturn the features of the Boston Housing dataset. This is a 13x506 Matrix of Float64 datatypes. The values are in the order [\"crim\",\"zn\",\"indus\",\"chas\",\"nox\",\"rm\",\"age\",\"dis\",\"rad\",\"tax\",\"ptratio\",\"b\",\"lstat\"]. It has 506 examples.\n\njulia> using MLDatasets: BostonHousing\n\njulia> features = BostonHousing.features();\n\njulia> summary(features)\n\"13×506 Matrix{Float64}\"\n\n\n\n\n\n","category":"function"},{"location":"datasets/BostonHousing/#MLDatasets.BostonHousing.targets","page":"Boston Housing","title":"MLDatasets.BostonHousing.targets","text":"targets(; dir = nothing)\n\nGet the targets for the Boston housing dataset,  a 506 element array listing the targets for each example.\n\njulia> using MLDatasets: BostonHousing\n\njulia> target = BostonHousing.targets();\n\njulia> summary(target)\n\"1×506 Matrix{Float64}\"\n\njulia> target[1]\n24.0\n\n\n\n\n\n","category":"function"},{"location":"datasets/UD_English/#UD-English","page":"UD_English","title":"UD English","text":"","category":"section"},{"location":"datasets/UD_English/","page":"UD_English","title":"UD_English","text":"The UD_English Universal Dependencies English Web Treebank dataset is an annotated corpus of morphological features, POS-tags and syntactic trees. The dataset follows CoNLL-style format.","category":"page"},{"location":"datasets/UD_English/","page":"UD_English","title":"UD_English","text":"traindata = UD_English.traindata()\ndevdata = UD_English.devdata()\ntestdata = UD_English.devdata()","category":"page"},{"location":"datasets/UD_English/#Data-Size","page":"UD_English","title":"Data Size","text":"","category":"section"},{"location":"datasets/UD_English/","page":"UD_English","title":"UD_English","text":" Train x Train y Test x Test y\nUD_English 12543 - 2077 -","category":"page"},{"location":"datasets/SVHN2/#SVHN2","page":"SVHN format 2","title":"The Street View House Numbers (SVHN) Dataset","text":"","category":"section"},{"location":"datasets/SVHN2/","page":"SVHN format 2","title":"SVHN format 2","text":"Description from the official website:","category":"page"},{"location":"datasets/SVHN2/","page":"SVHN format 2","title":"SVHN format 2","text":"SVHN is a real-world image dataset for developing machine learning and object recognition algorithms with minimal requirement on data preprocessing and formatting. It can be seen as similar in flavor to MNIST (e.g., the images are of small cropped digits), but incorporates an order of magnitude more labeled data (over 600,000 digit images) and comes from a significantly harder, unsolved, real world problem (recognizing digits and numbers in natural scene images). SVHN is obtained from house numbers in Google Street View images.","category":"page"},{"location":"datasets/SVHN2/","page":"SVHN format 2","title":"SVHN format 2","text":"About Format 2 (Cropped Digits):","category":"page"},{"location":"datasets/SVHN2/","page":"SVHN format 2","title":"SVHN format 2","text":"All digits have been resized to a fixed resolution of 32-by-32 pixels. The original character bounding boxes are extended in the appropriate dimension to become square windows, so that resizing them to 32-by-32 pixels does not introduce aspect ratio distortions. Nevertheless this preprocessing introduces some distracting digits to the sides of the digit of interest.","category":"page"},{"location":"datasets/SVHN2/","page":"SVHN format 2","title":"SVHN format 2","text":"note: Note\nFor non-commercial use only","category":"page"},{"location":"datasets/SVHN2/#Contents","page":"SVHN format 2","title":"Contents","text":"","category":"section"},{"location":"datasets/SVHN2/","page":"SVHN format 2","title":"SVHN format 2","text":"Pages = [\"SVHN2.md\"]\nDepth = 3","category":"page"},{"location":"datasets/SVHN2/#Overview","page":"SVHN format 2","title":"Overview","text":"","category":"section"},{"location":"datasets/SVHN2/","page":"SVHN format 2","title":"SVHN format 2","text":"The MLDatasets.SVHN2 sub-module provides a programmatic interface to download, load, and work with the SVHN2 dataset of handwritten digits.","category":"page"},{"location":"datasets/SVHN2/","page":"SVHN format 2","title":"SVHN format 2","text":"using MLDatasets\n\n# load full training set\ntrain_x, train_y = SVHN2.traindata()\n\n# load full test set\ntest_x,  test_y  = SVHN2.testdata()\n\n# load additional train set\nextra_x, extra_y = SVHN2.extradata()","category":"page"},{"location":"datasets/SVHN2/","page":"SVHN format 2","title":"SVHN format 2","text":"The provided functions also allow for optional arguments, such as the directory dir where the dataset is located, or the specific observation indices that one wants to work with. For more information on the interface take a look at the documentation (e.g. ?SVHN2.traindata).","category":"page"},{"location":"datasets/SVHN2/","page":"SVHN format 2","title":"SVHN format 2","text":"Function Description\ndownload([dir]) Trigger interactive download of the dataset\nclassnames() Return the class names as a vector of strings\ntraintensor([T], [indices]; [dir]) Load the training images as an array of eltype T\ntrainlabels([indices]; [dir]) Load the labels for the training images\ntraindata([T], [indices]; [dir]) Load images and labels of the training data\ntesttensor([T], [indices]; [dir]) Load the test images as an array of eltype T\ntestlabels([indices]; [dir]) Load the labels for the test images\ntestdata([T], [indices]; [dir]) Load images and labels of the test data\nextratensor([T], [indices]; [dir]) Load the extra images as an array of eltype T\nextralabels([indices]; [dir]) Load the labels for the extra training images\nextradata([T], [indices]; [dir]) Load images and labels of the extra training data","category":"page"},{"location":"datasets/SVHN2/","page":"SVHN format 2","title":"SVHN format 2","text":"This module also provides utility functions to make working with the SVHN (format 2) dataset in Julia more convenient.","category":"page"},{"location":"datasets/SVHN2/","page":"SVHN format 2","title":"SVHN format 2","text":"Function Description\nconvert2image(array) Convert the SVHN tensor/matrix to a colorant array","category":"page"},{"location":"datasets/SVHN2/","page":"SVHN format 2","title":"SVHN format 2","text":"To visualize an image or a prediction we provide the function convert2image to convert the given SVHN2 horizontal-major tensor (or feature matrix) to a vertical-major Colorant array.","category":"page"},{"location":"datasets/SVHN2/","page":"SVHN format 2","title":"SVHN format 2","text":"julia> SVHN2.convert2image(SVHN2.traindata(1)[1]) # first training image\n32×32 Array{RGB{N0f8},2}:\n[...]","category":"page"},{"location":"datasets/SVHN2/#API-Documentation","page":"SVHN format 2","title":"API Documentation","text":"","category":"section"},{"location":"datasets/SVHN2/","page":"SVHN format 2","title":"SVHN format 2","text":"SVHN2","category":"page"},{"location":"datasets/SVHN2/#MLDatasets.SVHN2","page":"SVHN format 2","title":"MLDatasets.SVHN2","text":"The Street View House Numbers (SVHN) Dataset\n\nAuthors: Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng\nWebsite: http://ufldl.stanford.edu/housenumbers\n\nSVHN was obtained from house numbers in Google Street View images. As such they are quite diverse in terms of orientation and image background. Similar to MNIST, SVHN has 10 classes (the digits 0-9), but unlike MNIST there is more data and the images are a little bigger (32x32 instead of 28x28) with an additional RGB color channel. The dataset is split up into three subsets: 73257 digits for training, 26032 digits for testing, and 531131 additional to use as extra training data.\n\nInterface\n\nSVHN2.traintensor, SVHN2.trainlabels, SVHN2.traindata\nSVHN2.testtensor, SVHN2.testlabels, SVHN2.testdata\nSVHN2.extratensor, SVHN2.extralabels, SVHN2.extradata\n\nUtilities\n\nSVHN2.download\nSVHN2.classnames\nSVHN2.convert2image\n\n\n\n\n\n","category":"module"},{"location":"datasets/SVHN2/#Trainingset","page":"SVHN format 2","title":"Trainingset","text":"","category":"section"},{"location":"datasets/SVHN2/","page":"SVHN format 2","title":"SVHN format 2","text":"SVHN2.traintensor\nSVHN2.trainlabels\nSVHN2.traindata","category":"page"},{"location":"datasets/SVHN2/#MLDatasets.SVHN2.traintensor","page":"SVHN format 2","title":"MLDatasets.SVHN2.traintensor","text":"traintensor([T = N0f8], [indices]; [dir]) -> Array{T}\n\nReturn the SVHN training images corresponding to the given indices as a multi-dimensional array of eltype T.\n\nThe image(s) is/are returned in the native vertical-major memory layout as a single numeric array. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1.\n\nIf the parameter indices is omitted or an AbstractVector, the images are returned as a 4D array (i.e. a Array{T,4}), in which the first dimension corresponds to the pixel columns (y) of the image, the second dimension to the pixel rows (x) of the image, the third dimension the RGB color channels, and the fourth dimension denotes the index of the image.\n\njulia> SVHN2.traintensor() # load all training images\n32×32×3×73257 Array{N0f8,4}:\n[...]\n\njulia> SVHN.traintensor(Float32, 1:3) # first three images as Float32\n32×32×3×3 Array{Float32,4}:\n[...]\n\nIf indices is an Integer, the single image is returned as Array{T,3} in vertical-major layout, which means that the first dimension denotes the pixel columns (y), the second dimension denotes the pixel rows (x), and the third dimension the RGB color channels of the image.\n\njulia> SVHN2.traintensor(1) # load first training image\n32×32×3 Array{N0f8,3}:\n[...]\n\nAs mentioned above, the color channel is encoded in the third dimension. You can use the utility function convert2image to convert an SVHN array into a Julia image with the appropriate RGB eltype.\n\njulia> SVHN2.convert2image(SVHN2.traintensor(1))\n32×32 Array{RGB{N0f8},2}:\n[...]\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing SVHN2 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/SVHN2. In the case that dir does not yet exist, a download prompt will be triggered. You can also use SVHN2.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/SVHN2/#MLDatasets.SVHN2.trainlabels","page":"SVHN format 2","title":"MLDatasets.SVHN2.trainlabels","text":"trainlabels([indices]; [dir])\n\nReturns the SVHN training labels corresponding to the given indices as an Int or Vector{Int}. The values of the labels denote the zero-based class-index that they represent (see SVHN2.classnames for the corresponding names). If indices is omitted, all labels are returned.\n\njulia> SVHN2.trainlabels() # full training set\n73257-element Array{Int64,1}:\n[...]\n\njulia> SVHN2.trainlabels(1:3) # first three labels\n3-element Array{Int64,1}:\n[...]\n\njulia> SVHN2.trainlabels(1) # first label\n[...]\n\njulia> SVHN2.classnames()[SVHN2.trainlabels(1)] # corresponding class\n[...]\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing SVHN2 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/SVHN2. In the case that dir does not yet exist, a download prompt will be triggered. You can also use SVHN2.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/SVHN2/#MLDatasets.SVHN2.traindata","page":"SVHN format 2","title":"MLDatasets.SVHN2.traindata","text":"traindata([T = N0f8], [indices]; [dir]) -> images, labels\n\nReturns the SVHN trainset corresponding to the given indices as a two-element tuple. If indices is omitted the full trainset is returned. The first element of the return values will be the images as a multi-dimensional array, and the second element the corresponding labels as integers.\n\nThe image(s) is/are returned in the native vertical-major memory layout as a single numeric array of eltype T. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1. You can use the utility function convert2image to convert an SVHN array into a Julia image with the appropriate RGB eltype. The integer values of the labels correspond 1-to-1 the digit that they represent with the exception of 0 which is encoded as 10.\n\nNote that because of the nature of how the dataset is stored on disk, SVHN2.traindata will always load the full trainset, regardless of which observations are requested. In the case indices are provided by the user, it will simply result in a sub-setting. This option is just provided for convenience.\n\nimages, labels = SVHN2.traindata() # full dataset\nimages, labels = SVHN2.traindata(2) # only second observation\nimages, labels = SVHN2.traindata(dir=\"./SVHN\") # custom folder\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing SVHN2 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/SVHN2. In the case that dir does not yet exist, a download prompt will be triggered. You can also use SVHN2.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/SVHN2/#Testset","page":"SVHN format 2","title":"Testset","text":"","category":"section"},{"location":"datasets/SVHN2/","page":"SVHN format 2","title":"SVHN format 2","text":"SVHN2.testtensor\nSVHN2.testlabels\nSVHN2.testdata","category":"page"},{"location":"datasets/SVHN2/#MLDatasets.SVHN2.testtensor","page":"SVHN format 2","title":"MLDatasets.SVHN2.testtensor","text":"testtensor([T = N0f8], [indices]; [dir]) -> Array{T}\n\nReturn the SVHN test images corresponding to the given indices as a multi-dimensional array of eltype T.\n\nThe image(s) is/are returned in the native vertical-major memory layout as a single numeric array. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1.\n\nIf the parameter indices is omitted or an AbstractVector, the images are returned as a 4D array (i.e. a Array{T,4}), in which the first dimension corresponds to the pixel columns (y) of the image, the second dimension to the pixel rows (x) of the image, the third dimension the RGB color channels, and the fourth dimension denotes the index of the image.\n\njulia> SVHN2.testtensor() # load all test images\n32×32×3×26032 Array{N0f8,4}:\n[...]\n\njulia> SVHN.testtensor(Float32, 1:3) # first three images as Float32\n32×32×3×3 Array{Float32,4}:\n[...]\n\nIf indices is an Integer, the single image is returned as Array{T,3} in vertical-major layout, which means that the first dimension denotes the pixel columns (y), the second dimension denotes the pixel rows (x), and the third dimension the RGB color channels of the image.\n\njulia> SVHN2.testtensor(1) # load first test image\n32×32×3 Array{N0f8,3}:\n[...]\n\nAs mentioned above, the color channel is encoded in the third dimension. You can use the utility function convert2image to convert an SVHN array into a Julia image with the appropriate RGB eltype.\n\njulia> SVHN2.convert2image(SVHN2.testtensor(1))\n32×32 Array{RGB{N0f8},2}:\n[...]\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing SVHN2 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/SVHN2. In the case that dir does not yet exist, a download prompt will be triggered. You can also use SVHN2.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/SVHN2/#MLDatasets.SVHN2.testlabels","page":"SVHN format 2","title":"MLDatasets.SVHN2.testlabels","text":"testlabels([indices]; [dir])\n\nReturns the SVHN test labels corresponding to the given indices as an Int or Vector{Int}. The values of the labels denote the zero-based class-index that they represent (see SVHN2.classnames for the corresponding names). If indices is omitted, all labels are returned.\n\njulia> SVHN2.testlabels() # full test set\n26032-element Array{Int64,1}:\n[...]\n\njulia> SVHN2.testlabels(1:3) # first three labels\n3-element Array{Int64,1}:\n[...]\n\njulia> SVHN2.testlabels(1) # first label\n[...]\n\njulia> SVHN2.classnames()[SVHN2.testlabels(1)] # corresponding class\n[...]\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing SVHN2 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/SVHN2. In the case that dir does not yet exist, a download prompt will be triggered. You can also use SVHN2.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/SVHN2/#MLDatasets.SVHN2.testdata","page":"SVHN format 2","title":"MLDatasets.SVHN2.testdata","text":"testdata([T = N0f8], [indices]; [dir]) -> images, labels\n\nReturns the SVHN testset corresponding to the given indices as a two-element tuple. If indices is omitted the full testset is returned. The first element of the return values will be the images as a multi-dimensional array, and the second element the corresponding labels as integers.\n\nThe image(s) is/are returned in the native vertical-major memory layout as a single numeric array of eltype T. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1. You can use the utility function convert2image to convert an SVHN array into a Julia image with the appropriate RGB eltype. The integer values of the labels correspond 1-to-1 the digit that they represent with the exception of 0 which is encoded as 10.\n\nNote that because of the nature of how the dataset is stored on disk, SVHN2.testdata will always load the full testset, regardless of which observations are requested. In the case indices are provided by the user, it will simply result in a sub-setting. This option is just provided for convenience.\n\nimages, labels = SVHN2.testdata() # full dataset\nimages, labels = SVHN2.testdata(2) # only second observation\nimages, labels = SVHN2.testdata(dir=\"./SVHN\") # custom folder\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing SVHN2 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/SVHN2. In the case that dir does not yet exist, a download prompt will be triggered. You can also use SVHN2.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/SVHN2/#Extraset","page":"SVHN format 2","title":"Extraset","text":"","category":"section"},{"location":"datasets/SVHN2/","page":"SVHN format 2","title":"SVHN format 2","text":"SVHN2.extratensor\nSVHN2.extralabels\nSVHN2.extradata","category":"page"},{"location":"datasets/SVHN2/#MLDatasets.SVHN2.extratensor","page":"SVHN format 2","title":"MLDatasets.SVHN2.extratensor","text":"extratensor([T = N0f8], [indices]; [dir]) -> Array{T}\n\nReturn the SVHN extra training images corresponding to the given indices as a multi-dimensional array of eltype T.\n\nThe image(s) is/are returned in the native vertical-major memory layout as a single numeric array. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1.\n\nIf the parameter indices is omitted or an AbstractVector, the images are returned as a 4D array (i.e. a Array{T,4}), in which the first dimension corresponds to the pixel columns (y) of the image, the second dimension to the pixel rows (x) of the image, the third dimension the RGB color channels, and the fourth dimension denotes the index of the image.\n\njulia> SVHN2.extratensor() # load all extra training images\n32×32×3×531131 Array{N0f8,4}:\n[...]\n\njulia> SVHN.extratensor(Float32, 1:3) # first three images as Float32\n32×32×3×3 Array{Float32,4}:\n[...]\n\nIf indices is an Integer, the single image is returned as Array{T,3} in vertical-major layout, which means that the first dimension denotes the pixel columns (y), the second dimension denotes the pixel rows (x), and the third dimension the RGB color channels of the image.\n\njulia> SVHN2.extratensor(1) # load first extra training image\n32×32×3 Array{N0f8,3}:\n[...]\n\nAs mentioned above, the color channel is encoded in the third dimension. You can use the utility function convert2image to convert an SVHN array into a Julia image with the appropriate RGB eltype.\n\njulia> SVHN2.convert2image(SVHN2.extratensor(1))\n32×32 Array{RGB{N0f8},2}:\n[...]\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing SVHN2 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/SVHN2. In the case that dir does not yet exist, a download prompt will be triggered. You can also use SVHN2.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/SVHN2/#MLDatasets.SVHN2.extralabels","page":"SVHN format 2","title":"MLDatasets.SVHN2.extralabels","text":"extralabels([indices]; [dir])\n\nReturns the SVHN extra training labels corresponding to the given indices as an Int or Vector{Int}. The values of the labels denote the zero-based class-index that they represent (see SVHN2.classnames for the corresponding names). If indices is omitted, all labels are returned.\n\njulia> SVHN2.extralabels() # full extra training set\n531131-element Array{Int64,1}:\n[...]\n\njulia> SVHN2.extralabels(1:3) # first three labels\n3-element Array{Int64,1}:\n[...]\n\njulia> SVHN2.extralabels(1) # first label\n[...]\n\njulia> SVHN2.classnames()[SVHN2.extralabels(1)] # corresponding class\n[...]\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing SVHN2 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/SVHN2. In the case that dir does not yet exist, a download prompt will be triggered. You can also use SVHN2.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/SVHN2/#MLDatasets.SVHN2.extradata","page":"SVHN format 2","title":"MLDatasets.SVHN2.extradata","text":"extradata([T = N0f8], [indices]; [dir]) -> images, labels\n\nReturns the SVHN extra trainset corresponding to the given indices as a two-element tuple. If indices is omitted the full extra trainset is returned. The first element of the return values will be the images as a multi-dimensional array, and the second element the corresponding labels as integers.\n\nThe image(s) is/are returned in the native vertical-major memory layout as a single numeric array of eltype T. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1. You can use the utility function convert2image to convert an SVHN array into a Julia image with the appropriate RGB eltype. The integer values of the labels correspond 1-to-1 the digit that they represent with the exception of 0 which is encoded as 10.\n\nNote that because of the nature of how the dataset is stored on disk, SVHN2.extradata will always load the full extra trainset, regardless of which observations are requested. In the case indices are provided by the user, it will simply result in a sub-setting. This option is just provided for convenience.\n\nimages, labels = SVHN2.extradata() # full dataset\nimages, labels = SVHN2.extradata(2) # only second observation\nimages, labels = SVHN2.extradata(dir=\"./SVHN\") # custom folder\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing SVHN2 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/SVHN2. In the case that dir does not yet exist, a download prompt will be triggered. You can also use SVHN2.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/SVHN2/#Utilities","page":"SVHN format 2","title":"Utilities","text":"","category":"section"},{"location":"datasets/SVHN2/","page":"SVHN format 2","title":"SVHN format 2","text":"SVHN2.download\nSVHN2.classnames\nSVHN2.convert2image","category":"page"},{"location":"datasets/SVHN2/#MLDatasets.SVHN2.download","page":"SVHN format 2","title":"MLDatasets.SVHN2.download","text":"download([dir]; [i_accept_the_terms_of_use])\n\nTrigger the (interactive) download of the full dataset into \"dir\". If no dir is provided the dataset will be downloaded into \"~/.julia/datadeps/SVHN2\".\n\nThis function will display an interactive dialog unless either the keyword parameter i_accept_the_terms_of_use or the environment variable DATADEPS_ALWAY_ACCEPT is set to true. Note that using the data responsibly and respecting copyright/terms-of-use remains your responsibility.\n\n\n\n\n\n","category":"function"},{"location":"datasets/SVHN2/#MLDatasets.SVHN2.classnames","page":"SVHN format 2","title":"MLDatasets.SVHN2.classnames","text":"classnames() -> Vector{Int}\n\nReturn the 10 digits for the SVHN classes as a vector of integers.\n\n\n\n\n\n","category":"function"},{"location":"datasets/SVHN2/#MLDatasets.SVHN2.convert2image","page":"SVHN format 2","title":"MLDatasets.SVHN2.convert2image","text":"convert2image(array) -> Array{RGB}\n\nConvert the given SVHN tensor in WHCN format (or feature vector/matrix) to a RGB array in HWN format.\n\njulia> SVHN2.convert2image(SVHN2.traindata()[1]) # full training dataset\n32×32×50000 Array{RGB{N0f8},3}:\n[...]\n\njulia> SVHN2.convert2image(SVHN2.traindata(1)[1]) # first training image\n32×32 Array{RGB{N0f8},2}:\n[...]\n\n\n\n\n\n","category":"function"},{"location":"datasets/SVHN2/#References","page":"SVHN format 2","title":"References","text":"","category":"section"},{"location":"datasets/SVHN2/","page":"SVHN format 2","title":"SVHN format 2","text":"Authors: Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng\nWebsite: http://ufldl.stanford.edu/housenumbers\n[Netzer et al., 2011] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng. \"Reading Digits in Natural Images with Unsupervised Feature Learning\" NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011","category":"page"},{"location":"containers/overview/#Dataset-Containers","page":"Data Containers","title":"Dataset Containers","text":"","category":"section"},{"location":"containers/overview/","page":"Data Containers","title":"Data Containers","text":"MLDatasets.jl contains several reusable data containers for accessing datasets in common storage formats. This feature is a work-in-progress and subject to change.","category":"page"},{"location":"containers/overview/","page":"Data Containers","title":"Data Containers","text":"FileDataset\nTableDataset\nHDF5Dataset\nBase.close(::HDF5Dataset)\nJLD2Dataset\nBase.close(::JLD2Dataset)\nCachedDataset\nMLDatasets.make_cache","category":"page"},{"location":"containers/overview/#MLDatasets.FileDataset","page":"Data Containers","title":"MLDatasets.FileDataset","text":"FileDataset([loadfn = FileIO.load,] paths)\nFileDataset([loadfn = FileIO.load,] dir, pattern = \"*\", depth = 4)\n\nWrap a set of file paths as a dataset (traversed in the same order as paths). Alternatively, specify a dir and collect all paths that match a glob pattern (recursively globbing by depth). The glob order determines the traversal order.\n\n\n\n\n\n","category":"type"},{"location":"containers/overview/#MLDatasets.TableDataset","page":"Data Containers","title":"MLDatasets.TableDataset","text":"TableDataset(table)\nTableDataset(path::AbstractString)\n\nWrap a Tables.jl-compatible table as a dataset container. Alternatively, specify the path to a CSV file directly to load it with CSV.jl + DataFrames.jl.\n\n\n\n\n\n","category":"type"},{"location":"containers/overview/#MLDatasets.HDF5Dataset","page":"Data Containers","title":"MLDatasets.HDF5Dataset","text":"HDF5Dataset(file::AbstractString, paths)\nHDF5Dataset(fid::HDF5.File, paths::Union{HDF5.Dataset, Vector{HDF5.Dataset}})\nHDF5Dataset(fid::HDF5.File, paths::Union{AbstractString, Vector{<:AbstractString}})\nHDF5Dataset(fid::HDF5.File, paths::Union{HDF5.Dataset, Vector{HDF5.Dataset}}, shapes)\n\nWrap several HDF5 datasets (paths) as a single dataset container. Each dataset p in paths should be accessible as fid[p]. Calling getobs on a HDF5Dataset returns a tuple with each element corresponding to the observation from each dataset in paths. See close(::HDF5Dataset) for closing the underlying HDF5 file pointer.\n\nFor array datasets, the last dimension is assumed to be the observation dimension. For scalar datasets, the stored value is returned by getobs for any index.\n\n\n\n\n\n","category":"type"},{"location":"containers/overview/#Base.close-Tuple{HDF5Dataset}","page":"Data Containers","title":"Base.close","text":"close(dataset::HDF5Dataset)\n\nClose the underlying HDF5 file pointer for dataset.\n\n\n\n\n\n","category":"method"},{"location":"containers/overview/#MLDatasets.JLD2Dataset","page":"Data Containers","title":"MLDatasets.JLD2Dataset","text":"JLD2Dataset(file::AbstractString, paths)\nJLD2Dataset(fid::JLD2.JLDFile, paths::Union{String, Vector{String}})\n\nWrap several JLD2 datasets (paths) as a single dataset container. Each dataset p in paths should be accessible as fid[p]. Calling getobs on a JLD2Dataset is equivalent to mapping getobs on each dataset in paths. See close(::JLD2Dataset) for closing the underlying JLD2 file pointer.\n\n\n\n\n\n","category":"type"},{"location":"containers/overview/#Base.close-Tuple{JLD2Dataset}","page":"Data Containers","title":"Base.close","text":"close(dataset::JLD2Dataset)\n\nClose the underlying JLD2 file pointer for dataset.\n\n\n\n\n\n","category":"method"},{"location":"containers/overview/#MLDatasets.CachedDataset","page":"Data Containers","title":"MLDatasets.CachedDataset","text":"CachedDataset(source, cachesize = numbobs(source))\nCachedDataset(source, cacheidx = 1:numbobs(source))\nCachedDataset(source, cacheidx, cache)\n\nWrap a source data container and cache cachesize samples in memory. This can be useful for improving read speeds when source is a lazy data container, but your system memory is large enough to store a sizeable chunk of it.\n\nBy default the observation indices 1:cachesize are cached. You can manually pass in a set of cacheidx as well.\n\nSee also make_cache for customizing the default cache creation for source.\n\n\n\n\n\n","category":"type"},{"location":"containers/overview/#MLDatasets.make_cache","page":"Data Containers","title":"MLDatasets.make_cache","text":"make_cache(source, cacheidx)\n\nReturn a in-memory copy of source at observation indices cacheidx. Defaults to getobs(source, cacheidx).\n\n\n\n\n\n","category":"function"},{"location":"utils/#Utils","page":"Utils","title":"Utils","text":"","category":"section"},{"location":"utils/","page":"Utils","title":"Utils","text":"MLDatasets.read_planetoid_data","category":"page"},{"location":"utils/#MLDatasets.read_planetoid_data","page":"Utils","title":"MLDatasets.read_planetoid_data","text":"Read any of the citation network datasets “Cora”, “CiteSeer” and “PubMed”  from the “Revisiting Semi-Supervised Learning with Graph Embeddings” paper.  Nodes represent documents and edges represent citation links. \n\nData collected from  https://github.com/kimiyoung/planetoid/raw/master/data\n\n\n\n\n\n","category":"function"},{"location":"datasets/graphs/#Graph-Datasets","page":"Graphs","title":"Graph Datasets","text":"","category":"section"},{"location":"datasets/graphs/","page":"Graphs","title":"Graphs","text":"Pages = [\"graphs.md\"]","category":"page"},{"location":"datasets/graphs/","page":"Graphs","title":"Graphs","text":"CiteSeer\nCiteSeer.dataset\nCora\nCora.dataset\nOGBDataset\nPolBlogs\nPolBlogs.edge_index\nPolBlogs.labels\nPubMed\nPubMed.dataset\nTUDataset","category":"page"},{"location":"datasets/graphs/#MLDatasets.CiteSeer","page":"Graphs","title":"MLDatasets.CiteSeer","text":"CiteSeer\n\nThe CiteSeer citation network dataset from Ref. [1]. Nodes represent documents and edges represent citation links. The dataset is designed for the node classification task.  The task is to predict the category of certain paper. The dataset is retrieved from Ref. [2].\n\nInterface\n\nCiteSeer.dataset\n\nReferences\n\n[1]: Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking [2]: Planetoid\n\n\n\n\n\n","category":"module"},{"location":"datasets/graphs/#MLDatasets.CiteSeer.dataset","page":"Graphs","title":"MLDatasets.CiteSeer.dataset","text":"dataset(; dir=nothing, reverse_edges=true)\n\nRetrieve the CiteSeer dataset. The output is a named tuple with fields\n\njulia> keys(CiteSeer.dataset())\n(:node_features, :node_labels, :adjacency_list, :train_indices, :val_indices, :test_indices, :num_classes, :num_nodes, :num_edges, :directed)\n\nIn particular, adjacency_list is a vector of vector,  where adjacency_list[i] will contain the neighbors of node i through outgoing edges.\n\nIf reverse_edges=true, the graph will contain the reverse of each edge and the graph will be undirected.\n\nSee also CiteSeer.\n\nUsage Examples\n\nusing MLDatasets: CiteSeer\ndata = CiteSeer.dataset()\ntrain_labels = data.node_labels[data.train_indices]\n\n\n\n\n\n","category":"function"},{"location":"datasets/graphs/#MLDatasets.Cora","page":"Graphs","title":"MLDatasets.Cora","text":"Cora\n\nThe Cora citation network dataset from Ref. [1]. Nodes represent documents and edges represent citation links. Each node has a predefined feature with 1433 dimensions.  The dataset is designed for the node classification task.  The task is to predict the category of certain paper. The dataset is retrieved from Ref. [2].\n\nStatistics\n\nNodes: 2708\nEdges: 10556\nNumber of Classes: 7\nLabel split:\nTrain:  140\nVal:    500\nTest:  1000\n\nThe split is the one used in the original paper [1] and  doesn't consider all nodes.\n\nInterface\n\nCora.dataset\n\nReferences\n\n[1]: Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking [2]: [Planetoid](https://github.com/kimiyoung/planetoid\n\n\n\n\n\n","category":"module"},{"location":"datasets/graphs/#MLDatasets.Cora.dataset","page":"Graphs","title":"MLDatasets.Cora.dataset","text":"dataset(; dir=nothing, reverse_edges=true)\n\nRetrieve the Cora dataset. The output is a named tuple with fields\n\njulia> keys(Cora.dataset())\n(:node_features, :node_labels, :adjacency_list, :train_indices, :val_indices, :test_indices, :num_classes, :num_nodes, :num_edges, :directed)\n\nIn particular, adjacency_list is a vector of vector,  where adjacency_list[i] will contain the neighbors of node i through outgoing edges.\n\nIf reverse_edges=true, the graph will contain the reverse of each edge and the graph will be undirected.\n\nSee also Cora.\n\nUsage Examples\n\nusing MLDatasets: Cora\n\ndata = Cora.dataset()\ntrain_labels = data.node_labels[data.train_indices]\n\n\n\n\n\n","category":"function"},{"location":"datasets/graphs/#MLDatasets.OGBDataset","page":"Graphs","title":"MLDatasets.OGBDataset","text":"OGBDataset(name; dir=nothing)\n\nThe collection of datasets from the Open Graph Benchmark: Datasets for Machine Learning on Graphs paper. \n\nname is the name  of one of the dasets (listed here) available for node prediction, edge prediction, or graph prediction tasks.\n\nThe OGBDataset type stores the graphs internally as dictionary objects.  The key \"edgeindex\" contains `2 x numedges`, where the first and second column contain the source and target nodes of each edge respectively.\n\nExamples\n\nNode prediction tasks\n\njulia> data = OGBDataset(\"ogbn-arxiv\")\nOGBDataset{Vector{Any}}:\n  name => ogbn-arxiv\n  path => /home/carlo/.julia/datadeps/OGBDataset/arxiv\n  metadata => Dict{String, Any} with 15 entries\n  graphs => 1-element Vector{Dict}\n  labels => 1-element Vector{Any}\n  split => Dict{String, Any} with 3 entries\n\n\njulia> data.metadata\nDict{String, Any} with 15 entries:\n  \"num classes\"           => 40\n  \"binary\"                => false\n  \"is hetero\"             => false\n  \"eval metric\"           => \"acc\"\n  \"task type\"             => \"multiclass classification\"\n  \"version\"               => 1\n  \"split\"                 => \"time\"\n  \"download_name\"         => \"arxiv\"\n  \"num tasks\"             => 1\n  \"url\"                   => \"http://snap.stanford.edu/ogb/data/nodeproppred/arxiv.zip\"\n  \"additional node files\" => \"node_year\"\n  \"add_inverse_edge\"      => false\n  \"has_node_attr\"         => true\n  \"additional edge files\" => nothing\n  \"has_edge_attr\"         => false\n\njulia> data.split\nDict{String, Any} with 3 entries:\n  \"test_idx\"  => [347, 399, 452, 481, 489, 491, 527, 538, 541, 603  …  169334, 169335, 169336, 169337, 169338, 169339, 169340, 169341, 169342, 169343]\n  \"train_idx\" => [1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  169110, 169112, 169113, 169114, 169115, 169116, 169118, 169146, 169149, 169252]\n  \"val_idx\"   => [350, 358, 367, 383, 394, 422, 430, 436, 468, 470  …  169089, 169096, 169108, 169111, 169128, 169156, 169177, 169186, 169262, 169297]\n\njulia> length(data)\n1\n\njulia> graph, labels = data[1];\n\njulia> graph\nDict{String, Any} with 6 entries:\n  \"edge_index\" => [104448 13092; 15859 47284; … ; 45119 162538; 45119 72718]\n  \"edge_feat\"  => nothing\n  \"node_feat\"  => Float32[-0.057943 -0.1245 … -0.138236 -0.029875; -0.05253 -0.070665 … 0.040885 0.268417; … ; -0.172796 -0.372111 … -0.041253 0.077647; -0.140059 -0.301036 … -0.376132 -0.091018]\n  \"num_nodes\"  => 169343\n  \"node_year\"  => [2013 2015 … 2020 2020]\n  \"num_edges\"  => 1166243\n\njulia> source, target = graph[\"edge_index][:,1], graph[\"edge_index][:,2];\n\nEdge prediction task\n\njulia> data = OGBDataset(\"ogbl-collab\")\nOGBDataset{Nothing}:\n  name => ogbl-collab\n  path => /home/carlo/.julia/datadeps/OGBDataset/collab\n  metadata => Dict{String, Any} with 13 entries\n  graphs => 1-element Vector{Dict}\n  labels => nothing\n  split => Dict{String, Any} with 3 entries\n\njulia> graph = data[1]  # no labels for this dataset\nDict{String, Any} with 7 entries:\n  \"edge_index\"  => [150990 224882; 150990 224882; … ; 221742 135759; 207233 140615]\n  \"edge_feat\"   => nothing\n  \"node_feat\"   => Float32[-0.177486 -0.237488 … 0.004236 -0.035025; -0.10298 0.022193 … 0.031942 -0.118059; … ; 0.003879 0.062124 … 0.05208 -0.176961; -0.276317 -0.081464 … -0.201557 -0.258715]\n  \"num_nodes\"   => 235868\n  \"edge_year\"   => [2004 2002 … 2006 1984; 2004 2002 … 2006 1984]\n  \"edge_weight\" => [2 1 … 1 1; 2 1 … 1 1]\n  \"num_edges\"   => 2358104\n\nGraph prediction task\n\njulia> data = OGBDataset(\"ogbg-molhiv\")\nOGBDataset{Matrix{Int64}}:\n  name => ogbg-molhiv\n  path => /home/carlo/.julia/datadeps/OGBDataset/molhiv\n  metadata => Dict{String, Any} with 15 entries\n  graphs => 41127-element Vector{Dict}\n  labels => 1×41127 Matrix{Int64}\n  split => Dict{String, Any} with 3 entries\n\njulia> length(data)\n41127\n\njulia> graph, labels = data[10]\n(Dict{String, Any}(\"edge_index\" => [-202 -201; -201 -200; … ; -198 -184; -201 -202], \"node_feat\" => Float32[7.0 6.0 … 7.0 7.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], \"edge_feat\" => Float32[0.0 0.0 … 0.0 1.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 1.0], \"num_nodes\" => 20, \"num_edges\" => 42), [0])\n\njulia> graph, labels = data[10];\n\njulia> graph\nDict{String, Any} with 5 entries:\n  \"edge_index\" => [1 2; 2 3; … ; 5 19; 2 1]\n  \"edge_feat\"  => Float32[0.0 0.0 … 0.0 1.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 1.0]\n  \"node_feat\"  => Float32[7.0 6.0 … 7.0 7.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n  \"num_nodes\"  => 20\n  \"num_edges\"  => 42\n\njulia> labels\n1-element Vector{Int64}:\n 0\n\n\n\n\n\n","category":"type"},{"location":"datasets/graphs/#MLDatasets.PolBlogs","page":"Graphs","title":"MLDatasets.PolBlogs","text":"PolBlogs\n\nThe Political Blogs dataset from the The Political Blogosphere and the 2004 US Election: Divided they Blog paper.\n\nPolBlogs is a graph with 1,490 vertices (representing political blogs) and 19,025 edges (links between blogs).\n\nThe links are automatically extracted from a crawl of the front page of the blog. \n\nEach vertex receives a label indicating the political leaning of the blog: liberal or conservative.\n\nInterface\n\nPolBlogs.edge_index\nPolBlogs.labels\n\n\n\n\n\n","category":"module"},{"location":"datasets/graphs/#MLDatasets.PolBlogs.edge_index","page":"Graphs","title":"MLDatasets.PolBlogs.edge_index","text":"edge_index(; dir = nothing)\n\nReturns a 19025 x 2 matrix containing edge indices where first column as source node and second column as target node together they represent an edge\n\nusing MLDatasets: PolBlogs\nadj = PolBlogs.edge_index()\n\n\n\n\n\n","category":"function"},{"location":"datasets/graphs/#MLDatasets.PolBlogs.labels","page":"Graphs","title":"MLDatasets.PolBlogs.labels","text":"labels(; dir = nothing)\n\nReturns a vector containing the 1490 labels.\n\nusing MLDatasets: PolBlogs\nlabels = PolBlogs.labels()\n\n\n\n\n\n","category":"function"},{"location":"datasets/graphs/#MLDatasets.PubMed","page":"Graphs","title":"MLDatasets.PubMed","text":"PubMed\n\nThe PubMed citation network dataset from Ref. [1]. Nodes represent documents and edges represent citation links. The dataset is designed for the node classification task.  The task is to predict the category of certain paper. The dataset is retrieved from Ref. [2].\n\nInterface\n\nPubMed.dataset\n\nReferences\n\n[1]: Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking [2]: Planetoid\n\n\n\n\n\n","category":"module"},{"location":"datasets/graphs/#MLDatasets.PubMed.dataset","page":"Graphs","title":"MLDatasets.PubMed.dataset","text":"dataset(; dir=nothing)\n\nRetrieve the PubMed dataset. The output is a named tuple with fields\n\njulia> keys(PubMed.dataset())\n(:node_features, :node_labels, :adjacency_list, :train_indices, :val_indices, :test_indices, :num_classes, :num_nodes, :num_edges, :directed)\n\nIn particular, adjacency_list is a vector of vector,  where adjacency_list[i] will contain the neighbors of node i through outgoing edges.\n\nIf reverse_edges=true, the graph will contain the reverse of each edge and the graph will be undirected.\n\nSee also PubMed.\n\nUsage Examples\n\nusing MLDatasets: PubMed\ndata = PubMed.dataset()\ntrain_labels = data.node_labels[data.train_indices]\n\n\n\n\n\n","category":"function"},{"location":"datasets/graphs/#MLDatasets.TUDataset","page":"Graphs","title":"MLDatasets.TUDataset","text":"TUDataset(name; dir=nothing)\n\nA variety of graph benchmark datasets, .e.g. \"QM9\", \"IMDB-BINARY\", \"REDDIT-BINARY\" or \"PROTEINS\", collected from the TU Dortmund University. Retrieve from TUDataset collection the dataset name, where name is any of the datasets available here. \n\nA TUDataset object can be indexed to retrieve a specific graph or a subset of graphs.\n\nInternal fields\n\nnum_nodes           # total number of nodes (considering all graphs)\nnum_edges           # total number of edges (considering all graphs)       \nnum_graphs          # total number of graphs\nsource              # vector of edges' source vectors      \ntarget              # vector of edges' target vectors\ngraph_indicator     # graph to which a node belongs too\nnode_labels\nedge_labels\ngraph_labels\nnode_attributes\nedge_attributes\ngraph_attributes\n\nSee here for an in-depth  description of the format. \n\nUsage Example\n\nusing MLDatasets: TUDataset\nusing LightGraphs: SimpleGraph, add_edge!\n\ndata = TUDataset(\"PROTEINS\")\n\n# Access first graph\nd1 = data[1] \n\n# Create a LightGraphs' graph\ng = SimpleGraph(d1.num_nodes)\nfor (s, t) in zip(d1.source, d1.target)\n    add_edge!(g, s, t)\nend\n\n# Node features\nX = d1.node_attributes # (nfeatures x nnodes) matrix\n\n\n\n\n\n","category":"type"},{"location":"datasets/SMSSpamCollection/#SMSSpamCollection","page":"SMSSpamCollection","title":"SMSSpamCollection","text":"","category":"section"},{"location":"datasets/SMSSpamCollection/","page":"SMSSpamCollection","title":"SMSSpamCollection","text":"SMSSpamCollection","category":"page"},{"location":"datasets/SMSSpamCollection/#MLDatasets.SMSSpamCollection","page":"SMSSpamCollection","title":"MLDatasets.SMSSpamCollection","text":"SMS Spam Collection v.1\n\nDESCRIPTION\n\n\n\nThe SMS Spam Collection v.1 (hereafter the corpus) is a set of SMS tagged messages that have been collected for SMS Spam research. It contains one set of SMS messages in English of 5,574 messages, tagged acording being ham (legitimate) or spam.\n\n1.1. Compilation\n\nThis corpus has been collected from free or free for research sources at the Web:\n\nA collection of between 425 SMS spam messages extracted manually from the Grumbletext Web site. This is a UK forum in which cell phone users make public claims about SMS spam messages, most of them without reporting the very spam message received. The identification of the text of spam messages in the claims is a very hard and time-consuming task, and it involved carefully scanning hundreds of web pages. The Grumbletext Web site is: http://www.grumbletext.co.uk/\nA list of 450 SMS ham messages collected from Caroline Tag's PhD Theses available at http://etheses.bham.ac.uk/253/1/Tagg09PhD.pdf\nA subset of 3,375 SMS ham messages of the NUS SMS Corpus (NSC), which is a corpus of about 10,000 legitimate messages collected for research at the Department of Computer Science at the National University of Singapore. The messages largely originate from Singaporeans and mostly from students attending the University. These messages were collected from volunteers who were made aware that their contributions were going to be made publicly available. The NUS SMS Corpus is avalaible at: http://www.comp.nus.edu.sg/~rpnlpir/downloads/corpora/smsCorpus/\nThe amount of 1,002 SMS ham messages and 322 spam messages extracted from the SMS Spam Corpus v.0.1 Big created by José María Gómez Hidalgo and public available at: http://www.esp.uem.es/jmgomez/smsspamcorpus/\n\n1.2. Statistics\n\nThere is one collection:\n\nThe SMS Spam Collection v.1 (text file: smsspamcollection) has a total of 4,827 SMS legitimate messages (86.6%) and a total of 747 (13.4%) spam messages.\n\n1.3. Format\n\nThe files contain one message per line. Each line is composed by two columns: one with label (ham or spam) and other with the raw text. Here are some examples:\n\nham   What you doing?how are you? ham   Ok lar... Joking wif u oni... ham   dun say so early hor... U c already then say... ham   MY NO. IN LUTON 0125698789 RING ME IF UR AROUND! H* ham   Siva is in hostel aha:-. ham   Cos i was out shopping wif darren jus now n i called him 2 ask wat present he wan lor. Then he started guessing who i was wif n he finally guessed darren lor. spam   FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! ubscribe6GBP/ mnth inc 3hrs 16 stop?txtStop spam   Sunshine Quiz! Win a super Sony DVD recorder if you canname the capital of Australia? Text MQUIZ to 82277. B spam   URGENT! Your Mobile No 07808726822 was awarded a L2,000 Bonus Caller Prize on 02/09/03! This is our 2nd attempt to contact YOU! Call 0871-872-9758 BOX95QU\n\nNote: messages are not chronologically sorted.\n\nUSAGE\n\n\n\nWe offer a comprehensive study of this corpus in the following paper that is under review. This work presents a number of statistics, studies and baseline results for several machine learning methods.\n\n[1] Almeida, T.A., Gómez Hidalgo, J.M., Yamakami, A. Contributions to the study of SMS Spam Filtering: New Collection and Results. Proceedings of the 2011 ACM Symposium on Document Engineering (ACM DOCENG'11), Mountain View, CA, USA, 2011. (Under review)\n\nABOUT\n\n\n\nThe corpus has been collected by Tiago Agostinho de Almeida (http://www.dt.fee.unicamp.br/~tiago) and José María Gómez Hidalgo (http://www.esp.uem.es/jmgomez).\n\nWe would like to thank Dr. Min-Yen Kan (http://www.comp.nus.edu.sg/~kanmy/) and his team for making the NUS SMS Corpus available. See: http://www.comp.nus.edu.sg/~rpnlpir/downloads/corpora/smsCorpus/. He is currently collecting a bigger SMS corpus at: http://wing.comp.nus.edu.sg:8080/SMSCorpus/\n\nLICENSE/DISCLAIMER\n\n\n\nWe would appreciate if:\n\nIn case you find this corpus useful, please make a reference to previous paper and the web page: http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/ in your papers, research, etc.\nSend us a message to tiago@dt.fee.unicamp.br in case you make use of the corpus.\n\nThe SMS Spam Collection v.1 is provided for free and with no limitations excepting:\n\nTiago Agostinho de Almeida and José María Gómez Hidalgo hold the copyrigth (c) for the SMS Spam Collection v.1.\nNo Warranty/Use At Your Risk. THE CORPUS IS MADE AT NO CHARGE. ACCORDINGLY, THE CORPUS IS PROVIDED AS IS,' WITHOUT WARRANTY OF ANY KIND, INCLUDING WITHOUT LIMITATION THE WARRANTIES THAT THEY ARE MERCHANTABLE, FIT FOR A PARTICULAR PURPOSE OR NON-INFRINGING. YOU ARE SOLELY RESPONSIBLE FOR YOUR USE, DISTRIBUTION, MODIFICATION, REPRODUCTION AND PUBLICATION OF THE CORPUS AND ANY DERIVATIVE WORKS THEREOF BY YOU AND ANY OF YOUR SUBLICENSEES (COLLECTIVELY,YOUR CORPUS USE'). THE ENTIRE RISK AS TO YOUR CORPUS USE IS BORNE BY YOU. YOU AGREE TO INDEMNIFY AND HOLD THE COPYRIGHT HOLDERS, AND THEIR AFFILIATES HARMLESS FROM ANY CLAIMS ARISING FROM OR RELATING TO YOUR CORPUS USE.\nLimitation of Liability. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR THEIR AFFILIATES, OR THE CORPUS CONTRIBUTING EDITORS, BE LIABLE FOR ANY INDIRECT, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES, INCLUDING, WITHOUT LIMITATION, DAMAGES FOR LOSS OF GOODWILL OR ANY AND ALL OTHER COMMERCIAL DAMAGES OR LOSSES, EVEN IF ADVISED OF THE POSSIBILITY THEREOF, AND REGARDLESS OF WHETHER ANY CLAIM IS BASED UPON ANY CONTRACT, TORT OR OTHER LEGAL OR EQUITABLE THEORY, RELATING OR ARISING FROM THE CORPUS, YOUR CORPUS USE OR THIS LICENSE AGREEMENT.\n\nInterface\n\nSMSSpamCollection.features\nSMSSpamCollection.targets\n\n\n\n\n\n","category":"module"},{"location":"datasets/SMSSpamCollection/#API-reference","page":"SMSSpamCollection","title":"API reference","text":"","category":"section"},{"location":"datasets/SMSSpamCollection/","page":"SMSSpamCollection","title":"SMSSpamCollection","text":"SMSSpamCollection.features\nSMSSpamCollection.targets","category":"page"},{"location":"datasets/SMSSpamCollection/#MLDatasets.SMSSpamCollection.features","page":"SMSSpamCollection","title":"MLDatasets.SMSSpamCollection.features","text":"features()\n\nReturn the features for the SMS Spam Collection dataset. It has 5574 rows, each containing a text message to be classified as spam or ham.\n\njulia> using MLDatasets: SMSSpamCollection\n\njulia> features = SMSSpamCollection.features();\n\njulia> summary(features)\n\"5574-element Vector{Any}\"\n\n\n\n\n\n","category":"function"},{"location":"datasets/SMSSpamCollection/#MLDatasets.SMSSpamCollection.targets","page":"SMSSpamCollection","title":"MLDatasets.SMSSpamCollection.targets","text":"targets()\n\nGet the targets for the SMS Spam Collection dataset, a 5574 element array listing the targets for each sample.\n\njulia> using MLDatasets: SMSSpamCollection\n\njulia> targets = SMSSpamCollection.targets();\n\njulia> summary(targets)\n\"5574-element Vector{Any}\"\n\njulia> targets[1]\n\"ham\"\n\n\n\n\n\n","category":"function"},{"location":"datasets/EMNIST/#EMNIST","page":"EMNIST","title":"EMNIST","text":"","category":"section"},{"location":"datasets/EMNIST/","page":"EMNIST","title":"EMNIST","text":"EMNIST packages 6 different extensions of the MNIST dataset involving letters and digits and variety of test train split options. Each extension has the standard test/train data/labels nested under it as shown below.","category":"page"},{"location":"datasets/EMNIST/","page":"EMNIST","title":"EMNIST","text":"using MLDatasets: EMNIST\n\ntraindata = EMNIST.Balanced.traindata()\ntestdata = EMNIST.Balanced.testdata()\ntrainlabels = EMNIST.Balanced.trainlabels()\ntestlabels = EMNIST.Balanced.testlabels()","category":"page"},{"location":"datasets/EMNIST/","page":"EMNIST","title":"EMNIST","text":"Dataset Classes traindata trainlabels testdata testlabels balanced classes\nByClass 62 697932x28x28 697932x1 116323x28x28 116323x1 no\nByMerge 47 697932x28x28 697932x1 116323x28x28 116323x1 no\nBalanced 47 112800x28x28 112800x1 18800x28x28 18800x1 yes\nLetters 26 124800x28x28 124800x1 20800x28x28 208000x1 yes\nDigits 10 240000x28x28 240000x1 40000x28x28 40000x1 yes\nMNIST 10 60000x28x28 60000x1 10000x28x28 10000x1 yes","category":"page"},{"location":"datasets/Titanic/#Titanic","page":"Titanic","title":"Titanic","text":"","category":"section"},{"location":"datasets/Titanic/","page":"Titanic","title":"Titanic","text":"Titanic","category":"page"},{"location":"datasets/Titanic/#MLDatasets.Titanic","page":"Titanic","title":"MLDatasets.Titanic","text":"Titanic Dataset.\n\nThe titanic and titanic2 data frames describe the survival status of individual passengers on the Titanic. \n\nThe titanic data frame does not contain information from the crew, but it does contain actual ages of half of the passengers.  The principal source for data about Titanic passengers is the Encyclopedia Titanica.  The datasets used here were begun by a variety of researchers.  One of the original sources is Eaton & Haas (1994)  Titanic: Triumph and Tragedy, Patrick Stephens Ltd, which includes a passenger list created by many researchers and edited by Michael A. Findlay.\n\nThe variables on our extracted dataset are pclass, survived, name, age, embarked, home.dest, room, ticket, boat, and sex.  pclass refers to passenger class (1st, 2nd, 3rd), and is a proxy for socio-economic class.  Age is in years, and some infants had fractional values.  The titanic2 data frame has no missing data and includes records for the crew, but age is dichotomized at adult vs. child.  These data were obtained from Robert Dawson, Saint Mary's University, E-mail.  The variables are pclass, age, sex, survived.  These data frames are useful for demonstrating many of the functions in Hmisc as well as  demonstrating binary logistic regression analysis using the Design library.  For more details and references see Simonoff, Jeffrey S (1997): The \"unusual episode\" and a second statistics course.  J Statistics Education, Vol. 5 No. 1. Thomas Cason of UVa has greatly updated and improved the titanic data frame  using the Encyclopedia Titanica and created a new dataset called titanic3.  These datasets reflects the state of data available as of 2 August 1999.  Some duplicate passengers have been dropped, many errors corrected, many missing ages filled in, and new variables created.\n\nDATASET specs\n\nNAME:\ttitanic3 TYPE:\tCensus SIZE:\t1309 Passengers, 14 Variables\n\nDESCRIPTIVE ABSTRACT:\n\nThe titanic3 data frame describes the survival status of individual passengers on the Titanic. The titanic3 data frame does not contain information for the crew, but it does contain actual and estimated ages for almost 80% of the passengers.\n\nSOURCES:\n\nHind, Philip. Encyclopedia Titanica. Online-only resource. Retrieved 01Feb2012 from http://www.encyclopedia-titanica.org/\n\nVARIABLE DESCRIPTIONS\n\nPclass\tPassenger Class (1 = 1st; 2 = 2nd; 3 = 3rd) survival\tSurvival (0 = No; 1 = Yes) name\tName sex\tSex age\tAge sibsp\tNumber of Siblings/Spouses Aboard parch\tNumber of Parents/Children Aboard ticket\tTicket Number fare\tPassenger Fare (British pound) cabin\tCabin embarked\tPort of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton) boat\tLifeboat body\tBody Identification Number home.dest\tHome/Destination\n\nSPECIAL NOTES\n\nPclass is a proxy for socio-economic status (SES) 1st ~ Upper; 2nd ~ Middle; 3rd ~ Lower\n\nAge is in Years; Fractional if Age less than One (1) If the Age is estimated, it is in the form xx.5\n\nFare is in Pre-1970 British Pounds () Conversion Factors: 1 = 12s = 240d and 1s = 20d\n\nWith respect to the family relation variables (i.e. sibsp and parch) some relations were ignored.  The following are the definitions used for sibsp and parch.\n\nSibling:\tBrother, Sister, Stepbrother, or Stepsister of Passenger Aboard Titanic Spouse:\tHusband or Wife of Passenger Aboard Titanic (Mistresses and Fiances Ignored) Parent:\tMother or Father of Passenger Aboard Titanic Child:\tSon, Daughter, Stepson, or Stepdaughter of Passenger Aboard Titanic\n\nOther family relatives excluded from this study include cousins, nephews/nieces, aunts/uncles, and in-laws.  Some children travelled only with a nanny, therefore parch=0 for them.      As well, some travelled with very close friends or neighbors in a village, however, the definitions do not support such relations.\n\nAn interesting result may be obtained using functions from the Hmisc library.\n\nattach\t(titanic3) plsmo\t(age, survived, group=sex, datadensity=T) \n\nor group=pclass plot\t(naclus\t(titanic3)) # study patterns of missing values summary\t(survived ~ age + sex + pclass + sibsp + parch, data=titanic3)\n\nInterface\n\nTitanic.features\nTitanic.targets\nTitanic.feature_names\n\n\n\n\n\n","category":"module"},{"location":"datasets/Titanic/#API-reference","page":"Titanic","title":"API reference","text":"","category":"section"},{"location":"datasets/Titanic/","page":"Titanic","title":"Titanic","text":"Titanic.feature_names\nTitanic.features\nTitanic.targets","category":"page"},{"location":"datasets/Titanic/#MLDatasets.Titanic.feature_names","page":"Titanic","title":"MLDatasets.Titanic.feature_names","text":"feature_names()\n\nReturn the  the names of the features provided in the dataset.\n\n\n\n\n\n","category":"function"},{"location":"datasets/Titanic/#MLDatasets.Titanic.features","page":"Titanic","title":"MLDatasets.Titanic.features","text":"features()\n\nReturn the features of the Titanic dataset. This is a 11x891 Matrix of containing both String and Float datatypes. The values are in the order [\"PassengerId\", \"Pclass\", \"Name\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"]. It has 891 examples.\n\njulia> using MLDatasets: Titanic\n\njulia> features = Titanic.features();\n\njulia> summary(features)\n\"11×891 Matrix{Any}\"\n\n\n\n\n\n","category":"function"},{"location":"datasets/Titanic/#MLDatasets.Titanic.targets","page":"Titanic","title":"MLDatasets.Titanic.targets","text":"targets(; dir = nothing)\n\nGet the targets for the Titanic dataset,  a 891 element array listing the targets for each example.\n\njulia> using MLDatasets: Titanic\n\njulia> target = Titanic.targets();\n\njulia> summary(target)\n\"1×891 Matrix{Any}\"\n\njulia> target[1]\n0\n\n\n\n\n\n","category":"function"},{"location":"datasets/Mutagenesis/#Mutagenesis","page":"Mutagenesis","title":"Mutagenesis","text":"","category":"section"},{"location":"datasets/Mutagenesis/","page":"Mutagenesis","title":"Mutagenesis","text":"Mutagenesis","category":"page"},{"location":"datasets/Mutagenesis/#MLDatasets.Mutagenesis","page":"Mutagenesis","title":"MLDatasets.Mutagenesis","text":"Mutagenesis\n\nWebsite: https://relational.fit.cvut.cz/dataset/Mutagenesis License: CC0\n\nThe Mutagenesis dataset comprises 188 molecules trialed for mutagenicity on Salmonella typhimurium, available from  relational.fit.cvut.cz and  CTUAvastLab/datasets.\n\nTrain, test and validation data can be loaded using following code. The withenv(\"DATADEPS_ALWAYS_ACCEPT\"=>\"true\") disables the accept download prompt.\n\njulia> using MLDatasets: Mutagenesis\n\njulia> train_x, train_y = withenv(\"DATADEPS_ALWAYS_ACCEPT\"=>\"true\") do; Mutagenesis.traindata(); end;\n\njulia> test_x, test_y = Mutagenesis.testdata();\n\njulia> val_x, val_y = Mutagenesis.valdata();\n\njulia> train_x[1]\nDict{Symbol, Any} with 5 entries:\n  :lumo  => -1.246\n  :inda  => 0\n  :logp  => 4.23\n  :ind1  => 1\n  :atoms => Dict{Symbol, Any}[Dict(:element=>\"c\", :bonds=>Dict{Symbol, Any}[Dic…\n\njulia> train_y[1]\n1\n\n\n\n\n\n","category":"module"},{"location":"LICENSE/#LICENSE","page":"LICENSE","title":"LICENSE","text":"","category":"section"},{"location":"LICENSE/","page":"LICENSE","title":"LICENSE","text":"using Markdown\nMarkdown.parse_file(joinpath(@__DIR__, \"..\", \"..\", \"LICENSE\"))","category":"page"},{"location":"datasets/CIFAR10/#CIFAR10","page":"CIFAR-10","title":"CIFAR-10","text":"","category":"section"},{"location":"datasets/CIFAR10/","page":"CIFAR-10","title":"CIFAR-10","text":"Description from the original website","category":"page"},{"location":"datasets/CIFAR10/","page":"CIFAR-10","title":"CIFAR-10","text":"The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.","category":"page"},{"location":"datasets/CIFAR10/#Contents","page":"CIFAR-10","title":"Contents","text":"","category":"section"},{"location":"datasets/CIFAR10/","page":"CIFAR-10","title":"CIFAR-10","text":"Pages = [\"CIFAR10.md\"]\nDepth = 3","category":"page"},{"location":"datasets/CIFAR10/#Overview","page":"CIFAR-10","title":"Overview","text":"","category":"section"},{"location":"datasets/CIFAR10/","page":"CIFAR-10","title":"CIFAR-10","text":"The MLDatasets.CIFAR10 sub-module provides a programmatic interface to download, load, and work with the CIFAR-10 dataset.","category":"page"},{"location":"datasets/CIFAR10/","page":"CIFAR-10","title":"CIFAR-10","text":"using MLDatasets\n\n# load full training set\ntrain_x, train_y = CIFAR10.traindata()\n\n# load full test set\ntest_x,  test_y  = CIFAR10.testdata()","category":"page"},{"location":"datasets/CIFAR10/","page":"CIFAR-10","title":"CIFAR-10","text":"The provided functions also allow for optional arguments, such as the directory dir where the dataset is located, or the specific observation indices that one wants to work with. For more information on the interface take a look at the documentation (e.g. ?CIFAR10.traindata).","category":"page"},{"location":"datasets/CIFAR10/","page":"CIFAR-10","title":"CIFAR-10","text":"Function Description\ndownload([dir]) Trigger interactive download of the dataset\nclassnames() Return the class names as a vector of strings\ntraintensor([T], [indices]; [dir]) Load the training images as an array of eltype T\ntrainlabels([indices]; [dir]) Load the labels for the training images\ntesttensor([T], [indices]; [dir]) Load the test images as an array of eltype T\ntestlabels([indices]; [dir]) Load the labels for the test images\ntraindata([T], [indices]; [dir]) Load images and labels of the training data\ntestdata([T], [indices]; [dir]) Load images and labels of the test data","category":"page"},{"location":"datasets/CIFAR10/","page":"CIFAR-10","title":"CIFAR-10","text":"This module also provides utility functions to make working with the CIFAR-10 dataset in Julia more convenient.","category":"page"},{"location":"datasets/CIFAR10/","page":"CIFAR-10","title":"CIFAR-10","text":"Function Description\nconvert2image(array) Convert the CIFAR-10 tensor/matrix to a colorant array","category":"page"},{"location":"datasets/CIFAR10/","page":"CIFAR-10","title":"CIFAR-10","text":"To visualize an image or a prediction we provide the function convert2image to convert the given CIFAR10 horizontal-major tensor (or feature matrix) to a vertical-major Colorant array.","category":"page"},{"location":"datasets/CIFAR10/","page":"CIFAR-10","title":"CIFAR-10","text":"julia> CIFAR10.convert2image(CIFAR10.traintensor(1)) # first training image\n32×32 Array{RGB{N0f8},2}:\n[...]","category":"page"},{"location":"datasets/CIFAR10/#API-Documentation","page":"CIFAR-10","title":"API Documentation","text":"","category":"section"},{"location":"datasets/CIFAR10/#Trainingset","page":"CIFAR-10","title":"Trainingset","text":"","category":"section"},{"location":"datasets/CIFAR10/","page":"CIFAR-10","title":"CIFAR-10","text":"CIFAR10.traintensor\nCIFAR10.trainlabels\nCIFAR10.traindata","category":"page"},{"location":"datasets/CIFAR10/#MLDatasets.CIFAR10.traintensor","page":"CIFAR-10","title":"MLDatasets.CIFAR10.traintensor","text":"traintensor([T = N0f8], [indices]; [dir]) -> Array{T}\n\nReturn the CIFAR-10 training images corresponding to the given indices as a multi-dimensional array of eltype T. If the corresponding labels are required as well, it is recommended to use CIFAR10.traindata instead.\n\nThe image(s) is/are returned in the horizontal-major memory layout as a single numeric array. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1.\n\nIf the parameter indices is omitted or an AbstractVector, the images are returned as a 4D array (i.e. a Array{T,4}) in WHCN format (width, height, #channels, #images).  For integer indices instead, a 3D array in WHC format is returned.\n\njulia> CIFAR10.traintensor() # load all training images\n32×32×3×50000 Array{N0f8,4}:\n[...]\n\njulia> CIFAR10.traintensor(Float32, 1:3) # first three images as Float32\n32×32×3×3 Array{Float32,4}:\n[...]\n\nIf indices is an Integer, a single image is returned as Array{T,3} array. \n\njulia> CIFAR10.traintensor(1) # load first training image\n32×32×3 Array{N0f8,3}:\n[...]\n\nYou can use the utility function convert2image to convert an CIFAR-10 array into a horizontal-major Julia image with the appropriate RGB eltype.\n\njulia> CIFAR10.convert2image(CIFAR10.traintensor(1)) # convert to column-major colorant array\n32×32 Array{RGB{N0f8},2}:\n[...]\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR10 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR10. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR10.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR10/#MLDatasets.CIFAR10.trainlabels","page":"CIFAR-10","title":"MLDatasets.CIFAR10.trainlabels","text":"trainlabels([indices]; [dir])\n\nReturns the CIFAR-10 trainset labels corresponding to the given indices as an Int or Vector{Int}. The values of the labels denote the zero-based class-index that they represent (see CIFAR10.classnames for the corresponding names). If indices is omitted, all labels are returned.\n\njulia> CIFAR10.trainlabels() # full training set\n50000-element Array{Int64,1}:\n 6\n 9\n ⋮\n 1\n 1\n\njulia> CIFAR10.trainlabels(1:3) # first three labels\n3-element Array{Int64,1}:\n 6\n 9\n 9\n\njulia> CIFAR10.trainlabels(1) # first label\n6\n\njulia> CIFAR10.classnames()[CIFAR10.trainlabels(1) + 1] # corresponding name\n\"frog\"\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR10 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR10. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR10.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR10/#MLDatasets.CIFAR10.traindata","page":"CIFAR-10","title":"MLDatasets.CIFAR10.traindata","text":"traindata([T = N0f8], [indices]; [dir]) -> images, labels\n\nReturns the CIFAR-10 trainingset corresponding to the given indices as a two-element tuple. If indices is omitted the full trainingset is returned. The first element of the return values will be the images as a multi-dimensional array, and the second element the corresponding labels as integers.\n\nThe image(s) is/are returned in horizontal-major memory layout as a single numeric array of eltype T. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1. The integer values of the labels correspond 1-to-1 the digit that they represent.\n\ntrain_x, train_y = CIFAR10.traindata() # full datatset\ntrain_x, train_y = CIFAR10.traindata(2) # only second observation\ntrain_x, train_y = CIFAR10.traindata(dir=\"./CIFAR10\") # custom folder\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR10 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR10. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR10.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\nTake a look at CIFAR10.traintensor and CIFAR10.trainlabels for more information.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR10/#Testset","page":"CIFAR-10","title":"Testset","text":"","category":"section"},{"location":"datasets/CIFAR10/","page":"CIFAR-10","title":"CIFAR-10","text":"CIFAR10.testtensor\nCIFAR10.testlabels\nCIFAR10.testdata","category":"page"},{"location":"datasets/CIFAR10/#MLDatasets.CIFAR10.testtensor","page":"CIFAR-10","title":"MLDatasets.CIFAR10.testtensor","text":"testtensor([T = N0f8], [indices]; [dir]) -> Array{T}\n\nReturn the CIFAR-10 test images corresponding to the given indices as a multi-dimensional array of eltype T. If the corresponding labels are required as well, it is recommended to use CIFAR10.testdata instead.\n\nImages are returned in horizontal-major memory layout as a single numeric array. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1.\n\nIf the parameter indices is omitted or an AbstractVector, the images are returned as a 4D array (i.e. a Array{T,4}) in WHCN format (width, height, #channels, #images).  For integer indices instead, a 3D array in WHC format is returned.\n\njulia> CIFAR10.testtensor() # load all training images\n32×32×3×10000 Array{N0f8,4}:\n[...]\n\njulia> CIFAR10.testtensor(Float32, 1:3) # first three images as Float32\n32×32×3×3 Array{Float32,4}:\n[...]\n\nIf indices is an Integer, a single image is returned as Array{T,3}.\n\njulia> CIFAR10.testtensor(1) # load first training image\n32×32×3 Array{N0f8,3}:\n[...]\n\nYou can use the utility function convert2image to convert an CIFAR-10 array into a horizontal-major HW Julia image with the appropriate RGB eltype.\n\njulia> CIFAR10.convert2image(CIFAR10.testtensor(1)) # convert to column-major colorant array\n32×32 Array{RGB{N0f8},2}:\n[...]\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR10 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR10. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR10.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR10/#MLDatasets.CIFAR10.testlabels","page":"CIFAR-10","title":"MLDatasets.CIFAR10.testlabels","text":"testlabels([indices]; [dir])\n\nReturns the CIFAR-10 testset labels corresponding to the given indices as an Int or Vector{Int}. The values of the labels denote the zero-based class-index that they represent (see CIFAR10.classnames for the corresponding names). If indices is omitted, all labels are returned.\n\njulia> CIFAR10.testlabels() # full training set\n10000-element Array{Int64,1}:\n 3\n 8\n ⋮\n 1\n 7\n\njulia> CIFAR10.testlabels(1:3) # first three labels\n3-element Array{Int64,1}:\n 3\n 8\n 8\n\njulia> CIFAR10.testlabels(1) # first label\n3\n\njulia> CIFAR10.classnames()[CIFAR10.testlabels(1) + 1] # corresponding name\n\"cat\"\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR10 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR10. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR10.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR10/#MLDatasets.CIFAR10.testdata","page":"CIFAR-10","title":"MLDatasets.CIFAR10.testdata","text":"testdata([T = N0f8], [indices]; [dir]) -> images, labels\n\nReturns the CIFAR-10 testset corresponding to the given indices as a two-element tuple. If indices is omitted the full testset is returned. The first element of the return values will be the images as a multi-dimensional array, and the second element the corresponding labels as integers.\n\nThe image(s) is/are returned in the horizontal-major memory layout as a single numeric array of eltype T. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1. The integer values of the labels correspond 1-to-1 the digit that they represent.\n\ntest_x, test_y = CIFAR10.testdata() # full datatset\ntest_x, test_y = CIFAR10.testdata(2) # only second observation\ntest_x, test_y = CIFAR10.testdata(dir=\"./CIFAR10\") # custom folder\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR10 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR10. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR10.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\nTake a look at CIFAR10.testtensor and CIFAR10.testlabels for more information.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR10/#Utilities","page":"CIFAR-10","title":"Utilities","text":"","category":"section"},{"location":"datasets/CIFAR10/","page":"CIFAR-10","title":"CIFAR-10","text":"CIFAR10.download\nCIFAR10.classnames\nCIFAR10.convert2image","category":"page"},{"location":"datasets/CIFAR10/#MLDatasets.CIFAR10.download","page":"CIFAR-10","title":"MLDatasets.CIFAR10.download","text":"download([dir]; [i_accept_the_terms_of_use])\n\nTrigger the (interactive) download of the full dataset into \"dir\". If no dir is provided the dataset will be downloaded into \"~/.julia/datadeps/CIFAR10\".\n\nThis function will display an interactive dialog unless either the keyword parameter i_accept_the_terms_of_use or the environment variable DATADEPS_ALWAYS_ACCEPT is set to true. Note that using the data responsibly and respecting copyright/terms-of-use remains your responsibility.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR10/#MLDatasets.CIFAR10.classnames","page":"CIFAR-10","title":"MLDatasets.CIFAR10.classnames","text":"classnames() -> Vector{String}\n\nReturn the 10 names for the CIFAR10 classes as a vector of strings.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR10/#MLDatasets.CIFAR10.convert2image","page":"CIFAR-10","title":"MLDatasets.CIFAR10.convert2image","text":"convert2image(array) -> Array{RGB}\n\nConvert the given CIFAR-10 horizontal-major tensor WHCN (or feature vector/matrix) to a vertical-major HWN RGB array.\n\njulia> CIFAR10.convert2image(CIFAR10.traintensor()) # full training dataset\n32×32×50000 Array{RGB{N0f8},3}:\n[...]\n\njulia> CIFAR10.convert2image(CIFAR10.traintensor(1)) # first training image\n32×32 Array{RGB{N0f8},2}:\n[...]\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR10/#References","page":"CIFAR-10","title":"References","text":"","category":"section"},{"location":"datasets/CIFAR10/","page":"CIFAR-10","title":"CIFAR-10","text":"Authors: Alex Krizhevsky, Vinod Nair, Geoffrey Hinton\nWebsite: https://www.cs.toronto.edu/~kriz/cifar.html\n[Krizhevsky, 2009] Alex Krizhevsky. \"Learning Multiple Layers of Features from Tiny Images\", Tech Report, 2009.","category":"page"},{"location":"datasets/CIFAR100/#CIFAR100","page":"CIFAR-100","title":"CIFAR-100","text":"","category":"section"},{"location":"datasets/CIFAR100/","page":"CIFAR-100","title":"CIFAR-100","text":"Description from the original website","category":"page"},{"location":"datasets/CIFAR100/","page":"CIFAR-100","title":"CIFAR-100","text":"The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.This dataset is just like the CIFAR-10, except it has 100 classes containing 600 images each. There are 500 training images and 100 testing images per class. The 100 classes in the CIFAR-100 are grouped into 20 superclasses. Each image comes with a \"fine\" label (the class to which it belongs) and a \"coarse\" label (the superclass to which it belongs).","category":"page"},{"location":"datasets/CIFAR100/#Contents","page":"CIFAR-100","title":"Contents","text":"","category":"section"},{"location":"datasets/CIFAR100/","page":"CIFAR-100","title":"CIFAR-100","text":"Pages = [\"CIFAR100.md\"]\nDepth = 3","category":"page"},{"location":"datasets/CIFAR100/#Overview","page":"CIFAR-100","title":"Overview","text":"","category":"section"},{"location":"datasets/CIFAR100/","page":"CIFAR-100","title":"CIFAR-100","text":"The MLDatasets.CIFAR100 sub-module provides a programmatic interface to download, load, and work with the CIFAR-100 dataset.","category":"page"},{"location":"datasets/CIFAR100/","page":"CIFAR-100","title":"CIFAR-100","text":"using MLDatasets\n\n# load full training set\ntrain_x, train_y_coarse, train_y_fine = CIFAR100.traindata()\n\n# load full test set\ntest_x, test_y_coarse, test_y_fine  = CIFAR100.testdata()","category":"page"},{"location":"datasets/CIFAR100/","page":"CIFAR-100","title":"CIFAR-100","text":"The provided functions also allow for optional arguments, such as the directory dir where the dataset is located, or the specific observation indices that one wants to work with. For more information on the interface take a look at the documentation (e.g. ?CIFAR100.traindata).","category":"page"},{"location":"datasets/CIFAR100/","page":"CIFAR-100","title":"CIFAR-100","text":"Function Description\ndownload([dir]) Trigger interactive download of the dataset\nclassnames_coarse(; [dir]) Return the 20 super-class names as a vector of strings\nclassnames_fine(; [dir]) Return the 100 class names as a vector of strings\ntraintensor([T], [indices]; [dir]) Load the training images as an array of eltype T\ntrainlabels([indices]; [dir]) Load the labels for the training images\ntesttensor([T], [indices]; [dir]) Load the test images as an array of eltype T\ntestlabels([indices]; [dir]) Load the labels for the test images\ntraindata([T], [indices]; [dir]) Load images and labels of the training data\ntestdata([T], [indices]; [dir]) Load images and labels of the test data","category":"page"},{"location":"datasets/CIFAR100/","page":"CIFAR-100","title":"CIFAR-100","text":"This module also provides utility functions to make working with the CIFAR-100 dataset in Julia more convenient.","category":"page"},{"location":"datasets/CIFAR100/","page":"CIFAR-100","title":"CIFAR-100","text":"Function Description\nconvert2image(array) Convert the CIFAR-100 tensor/matrix to a colorant array","category":"page"},{"location":"datasets/CIFAR100/","page":"CIFAR-100","title":"CIFAR-100","text":"To visualize an image or a prediction we provide the function convert2image to convert the given CIFAR-100 horizontal-major tensor (or feature matrix) to a vertical-major Colorant array.","category":"page"},{"location":"datasets/CIFAR100/","page":"CIFAR-100","title":"CIFAR-100","text":"julia> CIFAR100.convert2image(CIFAR100.traintensor(1)) # first training image\n32×32 Array{RGB{N0f8},2}:\n[...]","category":"page"},{"location":"datasets/CIFAR100/#API-Documentation","page":"CIFAR-100","title":"API Documentation","text":"","category":"section"},{"location":"datasets/CIFAR100/#Trainingset","page":"CIFAR-100","title":"Trainingset","text":"","category":"section"},{"location":"datasets/CIFAR100/","page":"CIFAR-100","title":"CIFAR-100","text":"CIFAR100.traintensor\nCIFAR100.trainlabels\nCIFAR100.traindata","category":"page"},{"location":"datasets/CIFAR100/#MLDatasets.CIFAR100.traintensor","page":"CIFAR-100","title":"MLDatasets.CIFAR100.traintensor","text":"traintensor([T = N0f8], [indices]; [dir]) -> Array{T}\n\nReturn the CIFAR-100 training images corresponding to the given indices as a multi-dimensional array of eltype T. If the corresponding labels are required as well, it is recommended to use CIFAR100.traindata instead.\n\nThe image(s) is/are returned in the native horizontal-major memory layout as a single numeric array. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1.\n\nIf the parameter indices is omitted or an AbstractVector, the images are returned as a 4D array (i.e. a Array{T,4}) in WHCN format (width, height, #channels, #images).  For integer indices instead, a 3D array in WHC format is returned.\n\njulia> CIFAR100.traintensor() # load all training images\n32×32×3×50000 Array{N0f8,4}:\n[...]\n\njulia> CIFAR100.traintensor(Float32, 1:3) # first three images as Float32\n32×32×3×3 Array{Float32,4}:\n[...]\n\nIf indices is an Integer, the single image is returned as Array{T,3}.\n\njulia> CIFAR100.traintensor(1) # load first training image\n32×32×3 Array{N0f8,3}:\n[...]\n\nYou can use the utility function convert2image to convert an CIFAR-100 array into a vertical-major Julia image with the appropriate RGB eltype.\n\njulia> CIFAR100.convert2image(CIFAR100.traintensor(1)) # convert to column-major colorant array\n32×32 Array{RGB{N0f8},2}:\n[...]\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR100 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR100. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR100.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR100/#MLDatasets.CIFAR100.trainlabels","page":"CIFAR-100","title":"MLDatasets.CIFAR100.trainlabels","text":"trainlabels([indices]; [dir]) -> Yc, Yf\n\nReturn the CIFAR-100 trainset labels (coarse and fine) corresponding to the given indices as a tuple of two Int or two Vector{Int}. The variables returned are the coarse label(s) (Yc) and the fine label(s) (Yf) respectively.\n\nYc, Yf = CIFAR100.trainlabels(); # full training set\n\nThe values of the labels denote the zero-based class-index that they represent (see CIFAR100.classnames_coarse and CIFAR100.classnames_fine for the corresponding names). If indices is omitted, all labels are returned.\n\njulia> Yc, Yf = CIFAR100.trainlabels(1:3) # first three labels\n([11, 15, 4], [19, 29, 0])\n\njulia> yc, yf = CIFAR100.trainlabels(1) # first label\n(11, 19)\n\njulia> CIFAR100.classnames_coarse()[yc + 1] # corresponding superclass name\n\"large_omnivores_and_herbivores\"\n\njulia> CIFAR100.classnames_fine()[yf + 1] # corresponding class name\n\"cattle\"\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR100 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR100. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR100.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR100/#MLDatasets.CIFAR100.traindata","page":"CIFAR-100","title":"MLDatasets.CIFAR100.traindata","text":"traindata([T = N0f8], [indices]; [dir]) -> X, Yc, Yf\n\nReturns the CIFAR-100 trainset corresponding to the given indices as a three-element tuple. If indices is omitted the full trainingset is returned. The first element of the three return values (X) will be the images as a multi-dimensional array, the second element (Yc) the corresponding coarse labels as integers, and the third element (Yf) the fine labels respectively.\n\nThe image(s) is/are returned in the native horizontal-major memory layout as a single numeric array of eltype T. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1. The integer values of the labels correspond 1-to-1 the digit that they represent.\n\nX, Yc, Yf = CIFAR100.traindata() # full datatset\nX, Yc, Yf = CIFAR100.traindata(dir=\"./CIFAR100\") # custom folder\nx, yc, yf = CIFAR100.traindata(2) # only second observation\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR100 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR100. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR100.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\nTake a look at CIFAR100.traintensor and CIFAR100.trainlabels for more information.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR100/#Testset","page":"CIFAR-100","title":"Testset","text":"","category":"section"},{"location":"datasets/CIFAR100/","page":"CIFAR-100","title":"CIFAR-100","text":"CIFAR100.testtensor\nCIFAR100.testlabels\nCIFAR100.testdata","category":"page"},{"location":"datasets/CIFAR100/#MLDatasets.CIFAR100.testtensor","page":"CIFAR-100","title":"MLDatasets.CIFAR100.testtensor","text":"testtensor([T = N0f8], [indices]; [dir]) -> Array{T}\n\nReturn the CIFAR-100 test images corresponding to the given indices as a multi-dimensional array of eltype T. If the corresponding labels are required as well, it is recommended to use CIFAR100.testdata instead.\n\nThe image(s) is/are returned in the native horizontal-major memory layout as a single numeric array. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1.\n\nIf the parameter indices is omitted or an AbstractVector, the images are returned as a 4D array (i.e. a Array{T,4}), in which the first dimension corresponds to the pixel columns (x) of the image, the second dimension to the pixel rows (y) of the image, the third dimension the RGB color channels, and the fourth dimension denotes the index of the image.\n\njulia> CIFAR100.testtensor() # load all training images\n32×32×3×10000 Array{N0f8,4}:\n[...]\n\njulia> CIFAR100.testtensor(Float32, 1:3) # first three images as Float32\n32×32×3×3 Array{Float32,4}:\n[...]\n\nIf indices is an Integer, the single image is returned as Array{T,3}.\n\njulia> CIFAR100.testtensor(1) # load first training image\n32×32×3 Array{N0f8,3}:\n[...]\n\nYou can use the utility function convert2image to convert an CIFAR-100 array into a vertical-major Julia image with the appropriate RGB eltype.\n\njulia> CIFAR100.convert2image(CIFAR100.testtensor(1)) # convert to column-major colorant array\n32×32 Array{RGB{N0f8},2}:\n[...]\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR100 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR100. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR100.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR100/#MLDatasets.CIFAR100.testlabels","page":"CIFAR-100","title":"MLDatasets.CIFAR100.testlabels","text":"testlabels([indices]; [dir]) -> Yc, Yf\n\nReturn the CIFAR-100 testset labels (coarse and fine) corresponding to the given indices as a tuple of two Int or two Vector{Int}. The variables returned are the coarse label(s) (Yc) and the fine label(s) (Yf) respectively.\n\nYc, Yf = CIFAR100.testlabels(); # full training set\n\nThe values of the labels denote the zero-based class-index that they represent (see CIFAR100.classnames_coarse and CIFAR100.classnames_fine for the corresponding names). If indices is omitted, all labels are returned.\n\njulia> Yc, Yf = CIFAR100.testlabels(1:3) # first three labels\n([10, 10, 0], [49, 33, 72])\n\njulia> yc, yf = CIFAR100.testlabels(1) # first label\n(10, 49)\n\njulia> CIFAR100.classnames_coarse()[yc + 1] # corresponding superclass name\n\"large_natural_outdoor_scenes\"\n\njulia> CIFAR100.classnames_fine()[yf + 1] # corresponding class name\n\"mountain\"\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR100 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR100. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR100.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR100/#MLDatasets.CIFAR100.testdata","page":"CIFAR-100","title":"MLDatasets.CIFAR100.testdata","text":"testdata([T = N0f8], [indices]; [dir]) -> X, Yc, Yf\n\nReturns the CIFAR-100 testset corresponding to the given indices as a three-element tuple. If indices is omitted the full testset is returned. The first element of the three return values (X) will be the images as a multi-dimensional array, the second element (Yc) the corresponding coarse labels as integers, and the third element (Yf) the fine labels respectively.\n\nThe image(s) is/are returned in the native horizontal-major memory layout as a single numeric array of eltype T. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1. The integer values of the labels correspond 1-to-1 the digit that they represent.\n\nX, Yc, Yf = CIFAR100.testdata() # full datatset\nX, Yc, Yf = CIFAR100.testdata(dir=\"./CIFAR100\") # custom folder\nx, yc, yf = CIFAR100.testdata(2) # only second observation\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR100 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR100. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR100.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\nTake a look at CIFAR100.testtensor and CIFAR100.testlabels for more information.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR100/#Utilities","page":"CIFAR-100","title":"Utilities","text":"","category":"section"},{"location":"datasets/CIFAR100/","page":"CIFAR-100","title":"CIFAR-100","text":"CIFAR100.download\nCIFAR100.classnames_coarse\nCIFAR100.classnames_fine","category":"page"},{"location":"datasets/CIFAR100/#MLDatasets.CIFAR100.download","page":"CIFAR-100","title":"MLDatasets.CIFAR100.download","text":"download([dir]; [i_accept_the_terms_of_use])\n\nTrigger the (interactive) download of the full dataset into \"dir\". If no dir is provided the dataset will be downloaded into \"~/.julia/datadeps/CIFAR100\".\n\nThis function will display an interactive dialog unless either the keyword parameter i_accept_the_terms_of_use or the environment variable DATADEPS_ALWAYS_ACCEPT is set to true. Note that using the data responsibly and respecting copyright/terms-of-use remains your responsibility.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR100/#MLDatasets.CIFAR100.classnames_coarse","page":"CIFAR-100","title":"MLDatasets.CIFAR100.classnames_coarse","text":"classnames_coarse(; [dir]) -> Vector{String}\n\nReturn the 20 names for the CIFAR100 superclasses as a vector of strings. Note that these strings are read from the actual resource file.\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR100 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR100. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR100.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR100/#MLDatasets.CIFAR100.classnames_fine","page":"CIFAR-100","title":"MLDatasets.CIFAR100.classnames_fine","text":"classnames_fine(; [dir]) -> Vector{String}\n\nReturn the 100 names for the CIFAR100 classes as a vector of strings. Note that these strings are read from the actual resource file.\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR100 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR100. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR100.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR100/","page":"CIFAR-100","title":"CIFAR-100","text":"See also CIFAR10.convert2image.","category":"page"},{"location":"datasets/CIFAR100/#References","page":"CIFAR-100","title":"References","text":"","category":"section"},{"location":"datasets/CIFAR100/","page":"CIFAR-100","title":"CIFAR-100","text":"Authors: Alex Krizhevsky, Vinod Nair, Geoffrey Hinton\nWebsite: https://www.cs.toronto.edu/~kriz/cifar.html\n[Krizhevsky, 2009] Alex Krizhevsky. \"Learning Multiple Layers of Features from Tiny Images\", Tech Report, 2009.","category":"page"},{"location":"#MLDatasets.jl's-Documentation","page":"Home","title":"MLDatasets.jl's Documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package represents a community effort to provide a common interface for accessing common Machine Learning (ML) datasets. In contrast to other data-related Julia packages, the focus of MLDatasets.jl is specifically on downloading, unpacking, and accessing benchmark dataset. Functionality for the purpose of data processing or visualization is only provided to a degree that is special to some dataset.","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package is a part of the JuliaML ecosystem. Its functionality is build on top of the package DataDeps.jl.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To install MLDatasets.jl, start up Julia and type the following code snippet into the REPL. It makes use of the native Julia package manger.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pkg.add(\"MLDatasets\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"Additionally, for example if you encounter any sudden issues, or in the case you would like to contribute to the package, you can manually choose to be on the latest (untagged) version.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pkg.checkout(\"MLDatasets\")","category":"page"},{"location":"#Basic-Usage","page":"Home","title":"Basic Usage","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The way MLDatasets.jl is organized is that each dataset has its own dedicated sub-module. Where possible, those sub-module share a common interface for interacting with the datasets. For example you can load the training set and the test set of the MNIST database of handwritten digits using the following commands:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using MLDatasets\n\ntrain_x, train_y = MNIST.traindata()\ntest_x,  test_y  = MNIST.testdata()","category":"page"},{"location":"","page":"Home","title":"Home","text":"To load the data the package looks for the necessary files in various locations (see DataDeps.jl for more information on how to configure such defaults). If the data can't be found in any of those locations, then the package will trigger a download dialog to ~/.julia/datadeps/MNIST. To overwrite this on a case by case basis, it is possible to specify a data directory directly in traindata(dir = <directory>) and testdata(dir = <directory>).","category":"page"},{"location":"datasets/Iris/#Iris","page":"Iris","title":"Iris","text":"","category":"section"},{"location":"datasets/Iris/","page":"Iris","title":"Iris","text":"Iris","category":"page"},{"location":"datasets/Iris/#MLDatasets.Iris","page":"Iris","title":"MLDatasets.Iris","text":"Fisher's classic iris dataset.\n\nMeasurements from 3 different species of iris: setosa, versicolor and virginica.  There are 50 examples of each species.\n\nThere are 4 measurements for each example: sepal length, sepal width, petal length and petal width.  The measurements are in centimeters.\n\nThe module retrieves the data from the UCI Machine Learning Repository.\n\nNOTE: no pre-defined train-test split for this dataset, features and labels return the whole dataset. \n\nInterface\n\nIris.features\nIris.labels\n\nUtilities\n\nIris.download\n\n\n\n\n\n","category":"module"},{"location":"datasets/Iris/#API-reference","page":"Iris","title":"API reference","text":"","category":"section"},{"location":"datasets/Iris/","page":"Iris","title":"Iris","text":"Iris.features\nIris.labels\nIris.download","category":"page"},{"location":"datasets/Iris/#MLDatasets.Iris.features","page":"Iris","title":"MLDatasets.Iris.features","text":"features(; dir = nothing)\n\nReturn a 4x150 matrix containing the 4-dimensional features of each observation.\n\n\n\n\n\n","category":"function"},{"location":"datasets/Iris/#MLDatasets.Iris.labels","page":"Iris","title":"MLDatasets.Iris.labels","text":"labels(; dir = nothing)\n\nReturn a string vector of length 150 containing observations' labels.\n\n\n\n\n\n","category":"function"},{"location":"datasets/Iris/#MLDatasets.Iris.download","page":"Iris","title":"MLDatasets.Iris.download","text":"download([dir]; [i_accept_the_terms_of_use])\n\nTrigger the (interactive) download of the full dataset into \"dir\". If no dir is provided the dataset will be downloaded into \"~/.julia/datadeps/Iris\".\n\nThis function will display an interactive dialog unless either the keyword parameter i_accept_the_terms_of_use or the environment variable DATADEPS_ALWAY_ACCEPT is set to true. Note that using the data responsibly and respecting copyright/terms-of-use remains your responsibility.\n\n\n\n\n\n","category":"function"},{"location":"datasets/PTBLM/#PTBLM","page":"PTBLM","title":"PTBLM","text":"","category":"section"},{"location":"datasets/PTBLM/","page":"PTBLM","title":"PTBLM","text":"The PTBLM dataset consists of Penn Treebank sentences for language modeling, available from tomsercu/lstm. The unknown words are replaced with <unk> so that the total vocabulary size becomes 10000.","category":"page"},{"location":"datasets/PTBLM/","page":"PTBLM","title":"PTBLM","text":"This is the first sentence of the PTBLM dataset.","category":"page"},{"location":"datasets/PTBLM/","page":"PTBLM","title":"PTBLM","text":"x, y = PTBLM.traindata()\n\nx[1]\n> [\"no\", \"it\", \"was\", \"n't\", \"black\", \"monday\"]\ny[1]\n> [\"it\", \"was\", \"n't\", \"black\", \"monday\", \"<eos>\"]","category":"page"},{"location":"datasets/PTBLM/","page":"PTBLM","title":"PTBLM","text":"where MLDataset adds the special word: <eos> to the end of y.","category":"page"}]
}
